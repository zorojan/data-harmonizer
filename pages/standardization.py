import streamlit as st
import pandas as pd
import re
import os
import numpy as np
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è
try:
    import quantulum3
    QUANTULUM_AVAILABLE = True
except ImportError:
    QUANTULUM_AVAILABLE = False

try:
    import pint
    ureg = pint.UnitRegistry()
    PINT_AVAILABLE = True
except ImportError:
    PINT_AVAILABLE = False

try:
    from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

st.title("üî¨ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")

# –í—Å–µ–≥–¥–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–∑ grouped_categories.csv
csv_path = os.path.join(os.path.dirname(__file__), '..', 'grouped_categories.csv')
try:
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º session state –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π
    if 'df_standardization' not in st.session_state:
        st.session_state['df_standardization'] = pd.read_csv(csv_path, encoding='utf-8-sig')
    df_param = st.session_state['df_standardization']
    st.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ grouped_categories.csv ({len(df_param)} —Å—Ç—Ä–æ–∫, {len(df_param.columns)} –∫–æ–ª–æ–Ω–æ–∫)")
except Exception as e:
    df_param = pd.DataFrame()
    st.session_state['df_standardization'] = df_param
    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å grouped_categories.csv: {e}")

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–µ—Ç–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ ---
st.sidebar.markdown("## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–µ—Ç–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞")

# –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è
st.sidebar.markdown("### üìè –ú–µ—Ç–æ–¥—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –µ–¥–∏–Ω–∏—Ü:")

use_quantulum = st.sidebar.checkbox(
    "üîç Quantulum3 (—Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –≤–µ–ª–∏—á–∏–Ω—ã)", 
    value=QUANTULUM_AVAILABLE,
    disabled=not QUANTULUM_AVAILABLE,
    help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –≤–µ–ª–∏—á–∏–Ω –∏ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞"
)

use_transformers = st.sidebar.checkbox(
    "ü§ñ Transformer-NER (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑)", 
    value=False,
    disabled=not TRANSFORMERS_AVAILABLE,
    help="–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π –∏ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è"
)

use_pint = st.sidebar.checkbox(
    "üìê Pint (–≤–∞–ª–∏–¥–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü)", 
    value=PINT_AVAILABLE,
    disabled=not PINT_AVAILABLE,
    help="–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è"
)

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
st.sidebar.markdown("### üéØ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
confidence_threshold = st.sidebar.slider(
    "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è", 
    min_value=0.1, 
    max_value=1.0, 
    value=0.7,
    help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"
)

max_samples = st.sidebar.number_input(
    "–ú–∞–∫—Å–∏–º—É–º –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", 
    min_value=5, 
    max_value=100, 
    value=20,
    help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–µ"
)

# –°—Ç–∞—Ç—É—Å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫
st.sidebar.markdown("### üìö –°—Ç–∞—Ç—É—Å –±–∏–±–ª–∏–æ—Ç–µ–∫:")
st.sidebar.success(f"‚úÖ Quantulum3: {'–î–æ—Å—Ç—É–ø–Ω–∞' if QUANTULUM_AVAILABLE else '–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'}")
st.sidebar.success(f"‚úÖ Transformers: {'–î–æ—Å—Ç—É–ø–Ω–∞' if TRANSFORMERS_AVAILABLE else '–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'}")
st.sidebar.success(f"‚úÖ Pint: {'–î–æ—Å—Ç—É–ø–Ω–∞' if PINT_AVAILABLE else '–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'}")

# --- –ü—Ä–æ—Å—Ç—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ ---

def analyze_column_statistics_simple(df, column):
    """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
    values = df[column].dropna()
    
    # –ü—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–∏—Ñ—Ä
    numeric_pattern = r'\d+\.?\d*'
    unit_pattern = r'(\d+\.?\d*)\s*([a-zA-Z–∞-—è—ë¬∞"\'\s]*)'
    
    numeric_count = 0
    units_found = Counter()
    numeric_values = []
    
    # –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –æ–±—Ä–∞–∑—Ü–∞ (–º–∞–∫—Å–∏–º—É–º 50 –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
    sample_size = min(50, len(values))
    
    for value in values.head(sample_size):
        if pd.isna(value):
            continue
            
        value_str = str(value).strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ü–∏—Ñ—Ä
        if re.search(numeric_pattern, value_str):
            numeric_count += 1
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–∞ –∏ –µ–¥–∏–Ω–∏—Ü—ã –ø—Ä–æ—Å—Ç—ã–º —Å–ø–æ—Å–æ–±–æ–º
            matches = re.findall(unit_pattern, value_str)
            for number, unit in matches:
                try:
                    numeric_values.append(float(number))
                    unit_clean = unit.strip()
                    if unit_clean and len(unit_clean) < 15:  # –†–∞–∑—É–º–Ω–∞—è –¥–ª–∏–Ω–∞ –µ–¥–∏–Ω–∏—Ü—ã
                        units_found[unit_clean] += 1
                except:
                    continue
    
    # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç "—á–∏—Å–ª–æ–≤–æ—Å—Ç–∏"
    numeric_percentage = (numeric_count / sample_size * 100) if sample_size > 0 else 0
    
    return {
        'total_values': len(values),
        'analyzed_values': sample_size,
        'numeric_count': numeric_count,
        'numeric_percentage': numeric_percentage,
        'units_found': dict(units_found.most_common(5)),
        'has_numeric': numeric_percentage > 20,  # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–æ–Ω–∫—É —á–∏—Å–ª–æ–≤–æ–π –µ—Å–ª–∏ >20% —Å–æ–¥–µ—Ä–∂–∞—Ç —Ü–∏—Ñ—Ä—ã
        'numeric_values': numeric_values[:10],  # –ü–µ—Ä–≤—ã–µ 10 —á–∏—Å–µ–ª –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
        'avg_value': sum(numeric_values) / len(numeric_values) if numeric_values else 0
    }

def quick_find_numeric_columns(df, columns_to_analyze):
    """–ë—ã—Å—Ç—Ä–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫"""
    numeric_columns = {}
    
    for column in columns_to_analyze:
        stats = analyze_column_statistics_simple(df, column)
        if stats['has_numeric']:
            numeric_columns[column] = stats
    
    return numeric_columns

def standardize_value_simple(value, target_format='number_unit', column_name=None, product_name=None, category=None):
    """–ü—Ä–æ—Å—Ç–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è"""
    if pd.isna(value):
        return value
    
    value_str = str(value).strip()
    
    # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω: —á–∏—Å–ª–æ + –µ–¥–∏–Ω–∏—Ü–∞
    pattern = r'(\d+\.?\d*)\s*([a-zA-Z–∞-—è—ë¬∞"\'\s]*)'
    match = re.search(pattern, value_str)
    
    if match:
        number = match.group(1)
        unit = match.group(2).strip()
        
        # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ –ø—É—Å—Ç–∞—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ª–æ–≥–∏–∫—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–¥–∏–Ω–∏—Ü
        if not unit and column_name:
            unit_from_context = extract_unit_from_context_optimized(column_name, product_name, category)
            if unit_from_context:
                unit = unit_from_context
        
        # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ –≤—Å–µ –µ—â–µ –ø—É—Å—Ç–∞—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not unit:
            return value
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
        if target_format == 'number_unit':
            return f"{number} {unit}"
        elif target_format == 'unit_number':
            return f"{unit} {number}"
        else:
            return f"{number} {unit}"
    
    return value

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä (—Å–∏–Ω–≥–ª—Ç–æ–Ω) ---
@st.cache_resource
def get_transformer_pipeline():
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Transformer-NER –º–æ–¥–µ–ª–∏"""
    if not TRANSFORMERS_AVAILABLE:
        return None
    
    try:
        return pipeline(
            "ner", 
            model="dbmdz/bert-large-cased-finetuned-conll03-english",
            aggregation_strategy="simple"
        )
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å Transformer –º–æ–¥–µ–ª—å: {e}")
        return None

# --- –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ ---

class IntelligentUnitExtractor:
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è"""
    
    def __init__(self):
        self.transformer_pipeline = get_transformer_pipeline() if use_transformers else None
    
    def extract_with_quantulum(self, text):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü —Å –ø–æ–º–æ—â—å—é Quantulum3 –∏ Pint"""
        if not QUANTULUM_AVAILABLE or not use_quantulum:
            return []
        
        try:
            parsed = quantulum3.parser.parse(str(text))
            results = []
            
            for quantity in parsed:
                if quantity.value and quantity.unit:
                    unit_name = quantity.unit.name
                    unit_symbol = getattr(quantity.unit, 'symbol', unit_name)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ–¥–∏–Ω–∏—Ü—É —á–µ—Ä–µ–∑ Pint –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
                    pint_validation = self.validate_with_pint(unit_symbol)
                    
                    if pint_validation and pint_validation.get('is_valid'):
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –µ–¥–∏–Ω–∏—Ü—É –æ—Ç Pint
                        canonical_unit = pint_validation.get('canonical_unit', unit_symbol)
                        dimension = pint_validation.get('dimensionality', quantity.unit.dimension.name if quantity.unit.dimension else '')
                        confidence = 0.95  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è Quantulum + Pint
                    else:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç Quantulum3
                        canonical_unit = unit_symbol
                        dimension = quantity.unit.dimension.name if quantity.unit.dimension else ''
                        confidence = 0.8  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ç–æ–ª—å–∫–æ –¥–ª—è Quantulum
                    
                    results.append({
                        'value': quantity.value,
                        'unit': canonical_unit,
                        'unit_symbol': canonical_unit,
                        'dimension': dimension,
                        'confidence': confidence,
                        'method': 'quantulum3_pint' if pint_validation and pint_validation.get('is_valid') else 'quantulum3',
                        'pint_validation': pint_validation
                    })
            
            return results
        except Exception as e:
            return []
    
    def extract_with_transformers(self, text):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü —Å –ø–æ–º–æ—â—å—é Transformer-NER –∏ Pint"""
        if not TRANSFORMERS_AVAILABLE or not use_transformers or not self.transformer_pipeline:
            return []
        
        try:
            # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —á–∏—Å–µ–ª —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏
            pattern = r'(\d+(?:\.\d+)?)\s*([a-zA-Z–∞-—è—ë¬∞"\'\s]+)'
            matches = re.findall(pattern, str(text).lower())
            
            results = []
            for value, unit in matches:
                try:
                    numeric_value = float(value)
                    unit_clean = unit.strip()
                    
                    if len(unit_clean) > 0 and len(unit_clean) < 20:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ–¥–∏–Ω–∏—Ü—É —á–µ—Ä–µ–∑ Pint
                        pint_validation = self.validate_with_pint(unit_clean)
                        
                        if pint_validation and pint_validation.get('is_valid'):
                            # –ï—Å–ª–∏ Pint —Ä–∞—Å–ø–æ–∑–Ω–∞–ª –µ–¥–∏–Ω–∏—Ü—É, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã—Å–æ–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                            confidence = 0.9 if pint_validation.get('method') == 'pint_exact' else 0.7
                            canonical_unit = pint_validation.get('canonical_unit', unit_clean)
                            
                            results.append({
                                'value': numeric_value,
                                'unit': canonical_unit,
                                'unit_symbol': canonical_unit,
                                'dimension': pint_validation.get('dimensionality', 'unknown'),
                                'confidence': confidence,
                                'method': 'transformers_pint',
                                'pint_validation': pint_validation
                            })
                        else:
                            # –ï—Å–ª–∏ Pint –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∏–∑–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                            results.append({
                                'value': numeric_value,
                                'unit': unit_clean,
                                'unit_symbol': unit_clean,
                                'dimension': 'unknown',
                                'confidence': 0.4,  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü
                                'method': 'transformers_only'
                            })
                except ValueError:
                    continue
            
            return results
        except Exception as e:
            return []
    
    def validate_with_pint(self, unit_string):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é Pint"""
        if not PINT_AVAILABLE or not use_pint:
            return None
        
        try:
            # –û—á–∏—Å—Ç–∫–∞ —Å—Ç—Ä–æ–∫–∏ –µ–¥–∏–Ω–∏—Ü—ã
            unit_clean = re.sub(r'[^\w¬∞]', '', str(unit_string).strip())
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
            try:
                unit = ureg.parse_expression(unit_clean)
                return {
                    'unit_str': str(unit),
                    'dimensionality': str(unit.dimensionality),
                    'is_valid': True,
                    'canonical_unit': str(unit.to_base_units().units),
                    'method': 'pint_exact'
                }
            except:
                pass
            
            # –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ –µ–¥–∏–Ω–∏—Ü—ã
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é Pint –¥–ª—è –ø–æ–∏—Å–∫–∞
            try:
                # –ü–æ–∏—Å–∫ –ø–æ —á–∞—Å—Ç–∏—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –≤ –±–∞–∑–µ Pint
                for unit_name in ureg._units.keys():
                    if unit_clean.lower() in str(unit_name).lower() or str(unit_name).lower() in unit_clean.lower():
                        unit = ureg.parse_expression(unit_name)
                        return {
                            'unit_str': str(unit),
                            'dimensionality': str(unit.dimensionality),
                            'is_valid': True,
                            'canonical_unit': str(unit.to_base_units().units),
                            'method': 'pint_fuzzy',
                            'original_input': unit_clean,
                            'matched_unit': unit_name
                        }
            except:
                pass
            
            return {'is_valid': False, 'method': 'pint', 'error': 'No match found'}
            
        except Exception as e:
            return {'is_valid': False, 'method': 'pint', 'error': str(e)}
    
    def extract_all_methods(self, text):
        """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ–º–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
        all_results = []
        
        # Quantulum3
        quantulum_results = self.extract_with_quantulum(text)
        all_results.extend(quantulum_results)
        
        # Transformers
        transformer_results = self.extract_with_transformers(text)
        all_results.extend(transformer_results)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å Pint
        for result in all_results:
            pint_validation = self.validate_with_pint(result['unit'])
            if pint_validation:
                result['pint_validation'] = pint_validation
        
        return all_results

def extract_numeric_values_intelligent(text):
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
    if pd.isna(text):
        return []
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    if not hasattr(extract_numeric_values_intelligent, '_extractor'):
        extract_numeric_values_intelligent._extractor = IntelligentUnitExtractor()
    
    extractor = extract_numeric_values_intelligent._extractor
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤
    results = extractor.extract_all_methods(text)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    filtered_results = [r for r in results if r.get('confidence', 0) >= confidence_threshold]
    
    return filtered_results

def detect_measurement_type_intelligent(column_name, values_sample):
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    if not hasattr(detect_measurement_type_intelligent, '_extractor'):
        detect_measurement_type_intelligent._extractor = IntelligentUnitExtractor()
    
    extractor = detect_measurement_type_intelligent._extractor
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—Ä–∞–∑—Ü—ã –∑–Ω–∞—á–µ–Ω–∏–π
    dimension_counter = Counter()
    unit_counter = Counter()
    
    for value in values_sample[:max_samples]:
        if pd.notna(value):
            extractions = extractor.extract_all_methods(value)
            
            for extraction in extractions:
                if extraction.get('confidence', 0) >= confidence_threshold:
                    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
                    dimension = extraction.get('dimension', 'unknown')
                    if dimension and dimension != 'unknown':
                        dimension_counter[dimension] += 1
                    
                    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –µ–¥–∏–Ω–∏—Ü—ã
                    unit = extraction.get('unit', '')
                    if unit:
                        unit_counter[unit] += 1
                    
                    # –ï—Å–ª–∏ –µ—Å—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—è Pint, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë
                    pint_val = extraction.get('pint_validation', {})
                    if pint_val.get('is_valid'):
                        pint_dimension = pint_val.get('dimensionality', '')
                        if pint_dimension:
                            dimension_counter[pint_dimension] += 2  # –ë–æ–ª—å—à–∏–π –≤–µ—Å –¥–ª—è Pint
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ç–∏–ø
    most_common_dimension = dimension_counter.most_common(1)
    most_common_unit = unit_counter.most_common(3)
    
    return {
        'primary_dimension': most_common_dimension[0][0] if most_common_dimension else 'unknown',
        'confidence': most_common_dimension[0][1] / len(values_sample) if most_common_dimension else 0,
        'common_units': [unit for unit, count in most_common_unit],
        'analysis_summary': {
            'dimensions_found': dict(dimension_counter),
            'units_found': dict(unit_counter)
        }
    }

def extract_unit_from_context_optimized(column_name, product_name=None, category=None):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Pint"""
    
    if not PINT_AVAILABLE:
        return None
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    column_lower = column_name.lower()
    product_lower = str(product_name).lower() if product_name else ""
    category_lower = str(category).lower() if category else ""
    
    # 1. –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ —Å–∫–æ–±–∫–∞—Ö (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
    bracket_match = re.search(r'\(([^)]+)\)', column_name)
    if bracket_match:
        potential_unit = bracket_match.group(1).strip()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ Pint
        try:
            ureg.parse_expression(potential_unit)
            return potential_unit
        except:
            pass
    
    # 2. –ò—â–µ–º –µ–¥–∏–Ω–∏—Ü—ã –≤ —Å–∞–º–æ–º –Ω–∞–∑–≤–∞–Ω–∏–∏ –∫–æ–ª–æ–Ω–∫–∏
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ —Å–ª–æ–≤–∞ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ —á–µ—Ä–µ–∑ Pint
    words = re.findall(r'\b\w+\b', column_lower)
    for word in words:
        if len(word) > 1:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–¥–Ω–æ—Å–∏–º–≤–æ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            try:
                ureg.parse_expression(word)
                return word
            except:
                continue
    
    # 3. –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ)
    context_text = f"{column_lower} {product_lower} {category_lower}"
    
    # –≠–∫—Ä–∞–Ω—ã –æ–±—ã—á–Ω–æ –≤ –¥—é–π–º–∞—Ö
    if any(screen_word in context_text for screen_word in ['screen', 'display', '—ç–∫—Ä–∞–Ω', '–¥–∏–∞–≥–æ–Ω–∞–ª—å']):
        try:
            ureg.parse_expression('inch')
            return 'inch'
        except:
            pass
    
    # –í–µ—Å –æ–±—ã—á–Ω–æ –≤ –∫–∏–ª–æ–≥—Ä–∞–º–º–∞—Ö
    if any(weight_word in context_text for weight_word in ['weight', '–≤–µ—Å']):
        try:
            ureg.parse_expression('kg')
            return 'kg'
        except:
            pass
    
    # –ú–æ—â–Ω–æ—Å—Ç—å –æ–±—ã—á–Ω–æ –≤ –≤–∞—Ç—Ç–∞—Ö
    if any(power_word in context_text for power_word in ['power', '–º–æ—â–Ω–æ—Å—Ç—å']):
        try:
            ureg.parse_expression('W')
            return 'W'
        except:
            pass
    
    # –ü–∞–º—è—Ç—å –æ–±—ã—á–Ω–æ –≤ –≥–∏–≥–∞–±–∞–π—Ç–∞—Ö
    if any(mem_word in context_text for mem_word in ['memory', 'storage', '–ø–∞–º—è—Ç—å']):
        try:
            ureg.parse_expression('GB')
            return 'GB'
        except:
            pass
    
    return None

# –ì—Ä—É–ø–ø–æ–≤–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
def analyze_units_by_category(df, column_name, category_column='group_name', sample_size=5):
    """–ê–Ω–∞–ª–∏–∑ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–π"""
    
    if not PINT_AVAILABLE:
        return {}
    
    category_units = {}
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    if category_column not in df.columns:
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—É—é –∫–æ–ª–æ–Ω–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        for alt_col in ['Category', 'category', 'group_name']:
            if alt_col in df.columns:
                category_column = alt_col
                break
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑
            return {'default': extract_unit_from_context_optimized(column_name, None, None)}
    
    for category, group_df in df.groupby(category_column):
        if pd.isna(category):
            continue
            
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –∏–∑ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        sample_values = group_df[column_name].dropna().head(sample_size)
        
        if len(sample_values) == 0:
            continue
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –µ–¥–∏–Ω–∏—Ü—É –¥–ª—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        category_unit = None
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –µ–¥–∏–Ω–∏—Ü—ã –∏–∑ —Å–∞–º–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        for value in sample_values:
            value_str = str(value).strip()
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω —á–∏—Å–ª–æ + –µ–¥–∏–Ω–∏—Ü–∞
            unit_match = re.search(r'\d+\.?\d*\s*([a-zA-Z–∞-—è—ë¬∞"\'\s]+)', value_str)
            if unit_match:
                potential_unit = unit_match.group(1).strip()
                if potential_unit and len(potential_unit) < 10:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ Pint
                    try:
                        ureg.parse_expression(potential_unit)
                        category_unit = potential_unit
                        break
                    except:
                        continue
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        if not category_unit:
            category_unit = extract_unit_from_context_optimized(column_name, None, str(category))
        
        if category_unit:
            category_units[str(category)] = category_unit
    
    return category_units

# –ö—ç—à –¥–ª—è –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –µ–¥–∏–Ω–∏—Ü
@st.cache_data
def get_category_units_cache(df_hash, column_name, category_column):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä—É–ø–ø–æ–≤–æ–π –∞–Ω–∞–ª–∏–∑ –µ–¥–∏–Ω–∏—Ü –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π DataFrame –∏–∑ —Ö—ç—à–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
    # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–Ω –≤–µ—Å—å DataFrame
    return {}

def standardize_value_intelligent_optimized(value, target_format=None, column_name=None, product_name=None, category=None, category_units=None):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è —Å –≥—Ä—É–ø–ø–æ–≤—ã–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –µ–¥–∏–Ω–∏—Ü"""
    if pd.isna(value):
        return value
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    if not hasattr(standardize_value_intelligent_optimized, '_extractor'):
        standardize_value_intelligent_optimized._extractor = IntelligentUnitExtractor()
    
    extractor = standardize_value_intelligent_optimized._extractor
    extractions = extractor.extract_all_methods(value)
    
    # –ï—Å–ª–∏ AI –Ω–µ –Ω–∞—à–µ–ª –µ–¥–∏–Ω–∏—Ü—ã –≤ –∑–Ω–∞—á–µ–Ω–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥—Ä—É–ø–ø–æ–≤–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü
    if not extractions and column_name:
        unit_from_category = None
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä—É–ø–ø–æ–≤–æ–π –∫—ç—à –µ–¥–∏–Ω–∏—Ü –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if category_units and category in category_units:
            unit_from_category = category_units[category]
        elif category_units and 'default' in category_units:
            unit_from_category = category_units['default']
        else:
            # Fallback –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É
            unit_from_category = extract_unit_from_context_optimized(column_name, product_name, category)
        
        if unit_from_category:
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ –∏–∑ –∑–Ω–∞—á–µ–Ω–∏—è
            value_str = str(value).strip()
            number_match = re.search(r'(\d+\.?\d*)', value_str)
            if number_match:
                number = float(number_match.group(1))
                
                # –°–æ–∑–¥–∞–µ–º "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–µ" –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                artificial_extraction = {
                    'value': number,
                    'unit': unit_from_category,
                    'unit_symbol': unit_from_category,
                    'dimension': 'from_category_group',
                    'confidence': 0.98,  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                    'method': 'category_group_analysis'
                }
                extractions = [artificial_extraction]
    
    if not extractions:
        return value
    
    # –ë–µ—Ä–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –Ω–∞–∏–≤—ã—Å—à–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
    best_extraction = max(extractions, key=lambda x: x.get('confidence', 0))
    
    if best_extraction.get('confidence', 0) < confidence_threshold:
        return value
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    number = best_extraction.get('value', '')
    unit = best_extraction.get('unit', '')
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—è Pint, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫—É—é –µ–¥–∏–Ω–∏—Ü—É
    pint_val = best_extraction.get('pint_validation', {})
    if pint_val.get('is_valid') and pint_val.get('canonical_unit'):
        unit = pint_val['canonical_unit']
    
    if target_format == 'number_unit':
        return f"{number} {unit}"
    elif target_format == 'unit_number':
        return f"{unit} {number}"
    else:
        return f"{number} {unit}"

def standardize_value_simple_optimized(value, target_format='number_unit', column_name=None, product_name=None, category=None, category_units=None):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ—Å—Ç–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è —Å –≥—Ä—É–ø–ø–æ–≤—ã–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –µ–¥–∏–Ω–∏—Ü"""
    if pd.isna(value):
        return value
    
    value_str = str(value).strip()
    
    # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω: —á–∏—Å–ª–æ + –µ–¥–∏–Ω–∏—Ü–∞
    pattern = r'(\d+\.?\d*)\s*([a-zA-Z–∞-—è—ë¬∞"\'\s]*)'
    match = re.search(pattern, value_str)
    
    if match:
        number = match.group(1)
        unit = match.group(2).strip()
        
        # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ –ø—É—Å—Ç–∞—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥—Ä—É–ø–ø–æ–≤–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü
        if not unit and column_name:
            unit_from_category = None
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä—É–ø–ø–æ–≤–æ–π –∫—ç—à –µ–¥–∏–Ω–∏—Ü –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            if category_units and category in category_units:
                unit_from_category = category_units[category]
            elif category_units and 'default' in category_units:
                unit_from_category = category_units['default']
            else:
                # Fallback –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É
                unit_from_category = extract_unit_from_context_optimized(column_name, product_name, category)
            
            if unit_from_category:
                unit = unit_from_category
        
        # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ –≤—Å–µ –µ—â–µ –ø—É—Å—Ç–∞—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not unit:
            return value
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
        if target_format == 'number_unit':
            return f"{number} {unit}"
        elif target_format == 'unit_number':
            return f"{unit} {number}"
        else:
            return f"{number} {unit}"
    
    return value

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞–∫–µ—Ç–Ω–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
def batch_standardize_column_optimized(df, column_name, standardization_format, use_ai=False, category_column='group_name'):
    """–ü–∞–∫–µ—Ç–Ω–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∫–æ–ª–æ–Ω–∫–∏ —Å –≥—Ä—É–ø–ø–æ–≤—ã–º –∞–Ω–∞–ª–∏–∑–æ–º –µ–¥–∏–Ω–∏—Ü"""
    
    # –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –µ–¥–∏–Ω–∏—Ü—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    category_units = analyze_units_by_category(df, column_name, category_column)
    
    results = []
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≥—Ä—É–ø–ø–∞–º –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    if category_column in df.columns:
        for category, group_df in df.groupby(category_column):
            if pd.isna(category):
                category = 'default'
            
            # –ü–æ–ª—É—á–∞–µ–º –µ–¥–∏–Ω–∏—Ü—É –¥–ª—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            category_unit = category_units.get(str(category))
            
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            for idx, value in group_df[column_name].items():
                if use_ai:
                    standardized = standardize_value_intelligent_optimized(
                        value, standardization_format, column_name, None, str(category), category_units
                    )
                else:
                    standardized = standardize_value_simple_optimized(
                        value, standardization_format, column_name, None, str(category), category_units
                    )
                results.append((idx, standardized))
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
        for idx, value in df[column_name].items():
            if use_ai:
                standardized = standardize_value_intelligent_optimized(
                    value, standardization_format, column_name, None, None, category_units
                )
            else:
                standardized = standardize_value_simple_optimized(
                    value, standardization_format, column_name, None, None, category_units
                )
            results.append((idx, standardized))
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –∏–Ω–¥–µ–∫—Å–æ–≤
    results_dict = dict(results)
    return [results_dict.get(idx, df.loc[idx, column_name]) for idx in df.index]

def analyze_column_statistics_intelligent(df, column):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–æ–ª–æ–Ω–∫–∏"""
    values = df[column].dropna()
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    extraction_stats = {
        'quantulum_extractions': 0,
        'transformer_extractions': 0,
        'pint_validations': 0,
        'total_extractions': 0
    }
    
    numeric_values = []
    units_found = Counter()
    dimensions_found = Counter()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    if not hasattr(analyze_column_statistics_intelligent, '_extractor'):
        analyze_column_statistics_intelligent._extractor = IntelligentUnitExtractor()
    
    extractor = analyze_column_statistics_intelligent._extractor
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—Ä–∞–∑–µ—Ü –∑–Ω–∞—á–µ–Ω–∏–π
    sample_size = min(max_samples, len(values))
    for value in values.head(sample_size):
        extractions = extractor.extract_all_methods(value)
        
        extraction_stats['total_extractions'] += len(extractions)
        
        for extraction in extractions:
            method = extraction.get('method', 'unknown')
            if method == 'quantulum3':
                extraction_stats['quantulum_extractions'] += 1
            elif method == 'transformers':
                extraction_stats['transformer_extractions'] += 1
            
            if extraction.get('pint_validation', {}).get('is_valid'):
                extraction_stats['pint_validations'] += 1
            
            if extraction.get('confidence', 0) >= confidence_threshold:
                numeric_values.append(extraction.get('value', 0))
                units_found[extraction.get('unit', '')] += 1
                
                dimension = extraction.get('dimension', '')
                if dimension:
                    dimensions_found[dimension] += 1
    
    stats = {
        'total_values': len(values),
        'analyzed_values': sample_size,
        'numeric_count': len(numeric_values),
        'extraction_stats': extraction_stats,
        'units_found': dict(units_found.most_common(10)),
        'dimensions_found': dict(dimensions_found.most_common(5)),
        'numeric_stats': {}
    }
    
    if numeric_values:
        stats['numeric_stats'] = {
            'min': min(numeric_values),
            'max': max(numeric_values),
            'mean': sum(numeric_values) / len(numeric_values),
            'count': len(numeric_values)
        }
    
    return stats

# --- –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---

if not df_param.empty:
    st.dataframe(df_param.head(20))
    all_columns = list(df_param.columns)

    # –ò—Å–∫–ª—é—á–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
    system_columns = [
        col for col in all_columns
        if any(keyword in col.lower() for keyword in [
            'name', 'id', 'source_file', 'category', 'group_name',  # —Å–∏—Å—Ç–µ–º–Ω—ã–µ
            'sku', 'width',  # –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            'price', 'cost', '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å'  # —Ü–∏—Ñ—Ä–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        ])
    ]

    st.markdown("#### –ò—Å–∫–ª—é—á–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞")
    excluded_cols = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å:",
        options=all_columns,
        default=system_columns,
        help="–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–∫–ª—é—á–µ–Ω—ã: —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏, SKU, Width, —Ü–µ–Ω—ã"
    )

    analysis_columns = [c for c in all_columns if c not in excluded_cols]
    
    if analysis_columns:
        st.success(f"‚úÖ –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ—Å—Ç—É–ø–Ω–æ {len(analysis_columns)} –∫–æ–ª–æ–Ω–æ–∫: {', '.join(analysis_columns[:5])}{'...' if len(analysis_columns) > 5 else ''}")
    else:
        st.warning("‚ùå –ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –í—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω—ã.")
    
    # --- –≠—Ç–∞–ø 1: –ë—ã—Å—Ç—Ä–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ ---
    with st.expander("#### 1. üî¢ –ë—ã—Å—Ç—Ä–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫", expanded=True):
        st.markdown("**–ü–æ–∏—Å–∫ –∫–æ–ª–æ–Ω–æ–∫ —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö —Ü–∏—Ñ—Ä—ã –∏–ª–∏ —Ü–∏—Ñ—Ä—ã + –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è**")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã –ò–ò –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —ç—Ç–∞–ø–æ–≤
        active_methods = []
        if use_quantulum:
            active_methods.append("üîç Quantulum3")
        if use_transformers:
            active_methods.append("ü§ñ Transformer-NER")
        if use_pint:
            active_methods.append("üìê Pint")
        
        if active_methods:
            st.info(f"–ú–µ—Ç–æ–¥—ã –ò–ò –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —ç—Ç–∞–ø–æ–≤: {', '.join(active_methods)}")
            if use_transformers and TRANSFORMERS_AVAILABLE:
                st.info("‚ÑπÔ∏è Transformer –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è)")
        
        if st.button("üîç –ù–∞–π—Ç–∏ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏", key="find_numeric_simple"):
            if not analysis_columns:
                st.warning("–ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è.")
            else:
                with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫–∏..."):
                    # –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑
                    numeric_analysis = quick_find_numeric_columns(df_param, analysis_columns)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    st.session_state['numeric_analysis_simple'] = numeric_analysis
                    
                    if numeric_analysis:
                        st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(numeric_analysis)} –∫–æ–ª–æ–Ω–æ–∫ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏!")
                    else:
                        st.warning("‚ùå –ö–æ–ª–æ–Ω–∫–∏ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ—Å—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        if 'numeric_analysis_simple' in st.session_state and st.session_state['numeric_analysis_simple']:
            st.markdown("**üìä –ù–∞–π–¥–µ–Ω–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏**")
            
            analysis_data = []
            for column, stats in st.session_state['numeric_analysis_simple'].items():
                row = {
                    '–ö–æ–ª–æ–Ω–∫–∞': column,
                    '–í—Å–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–π': stats['total_values'],
                    '–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ': stats['analyzed_values'],
                    '–° —Ü–∏—Ñ—Ä–∞–º–∏': stats['numeric_count'],
                    '% —á–∏—Å–ª–æ–≤—ã—Ö': f"{stats['numeric_percentage']:.1f}%",
                    '–ù–∞–π–¥–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã': ', '.join(list(stats['units_found'].keys())[:3]),
                    '–ü—Ä–∏–º–µ—Ä—ã —á–∏—Å–µ–ª': ', '.join([str(v) for v in stats['numeric_values'][:3]]),
                    '–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ': f"{stats['avg_value']:.2f}" if stats['avg_value'] > 0 else "-"
                }
                analysis_data.append(row)
            
            analysis_df = pd.DataFrame(analysis_data)
            st.dataframe(analysis_df, use_container_width=True)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏
            selected_col = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ø—Ä–∏–º–µ—Ä–æ–≤:",
                options=list(st.session_state['numeric_analysis_simple'].keys())
            )
            
            if selected_col:
                st.markdown(f"**–ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ '{selected_col}':**")
                sample_values = df_param[selected_col].dropna().head(10).tolist()
                for i, value in enumerate(sample_values, 1):
                    # –ü–æ–¥—Å–≤–µ—á–∏–≤–∞–µ–º —Ü–∏—Ñ—Ä—ã –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö
                    value_str = str(value)
                    highlighted = re.sub(r'(\d+\.?\d*)', r'**\1**', value_str)
                    st.write(f"{i}. {highlighted}")

    # --- –≠—Ç–∞–ø 2: –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π ---
    with st.expander("#### 2. ‚öôÔ∏è –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π", expanded=False):
        
        if 'numeric_analysis_simple' in st.session_state and st.session_state['numeric_analysis_simple']:
            
            # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
            col1, col2 = st.columns([1, 2])
            with col1:
                use_ai_standardization = st.checkbox(
                    "üß† –£–º–Ω–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è (AI)", 
                    value=False,
                    help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å AI –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏"
                )
            with col2:
                if use_ai_standardization:
                    st.info("ü§ñ AI-—Ä–µ–∂–∏–º: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü")
                else:
                    st.info("‚ö° –ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º: –ø—Ä–æ—Å—Ç–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ regex")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            st.info("üöÄ **–ì—Ä—É–ø–ø–æ–≤–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: –°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –∏–∑ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–≤–∞—Ä–æ–≤, –∞ –∑–∞—Ç–µ–º –ø—Ä–∏–º–µ–Ω—è–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã –∫–æ –≤—Å–µ–º —Ç–æ–≤–∞—Ä–∞–º –≤ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ 'laptop' –ø–∞—Ä–∞–º–µ—Ç—Ä 'Screen Inches' –∏–º–µ–µ—Ç –µ–¥–∏–Ω–∏—Ü—É 'inches' —É 2-3 —Ç–æ–≤–∞—Ä–æ–≤, —Ç–æ –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –Ω–æ—É—Ç–±—É–∫–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª—É—á–∞—Ç —ç—Ç—É –∂–µ –µ–¥–∏–Ω–∏—Ü—É.")
            
            # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
            standardizable_columns = list(st.session_state['numeric_analysis_simple'].keys())
            selected_columns = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏:",
                options=standardizable_columns,
                default=standardizable_columns[:3] if len(standardizable_columns) > 3 else standardizable_columns
            )
            
            if selected_columns:
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
                format_options = {
                    'number_unit': '–ß–∏—Å–ª–æ –ï–¥–∏–Ω–∏—Ü–∞ (100 kg)',
                    'unit_number': '–ï–¥–∏–Ω–∏—Ü–∞ –ß–∏—Å–ª–æ (kg 100)'
                }
                
                if use_ai_standardization:
                    format_options['auto'] = '–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ (AI)'
                
                standardization_format = st.selectbox(
                    "–§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:",
                    options=list(format_options.keys()),
                    format_func=lambda x: format_options[x],
                    index=0
                )
                
                # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
                if st.button("üëÅÔ∏è –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏", key="preview_standardization"):
                    preview_col = selected_columns[0]
                    st.markdown(f"**–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ '{preview_col}':**")
                    
                    sample_values = df_param[preview_col].dropna().head(5)
                    for i, (idx, original) in enumerate(sample_values.items()):
                        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–µ
                        product_name = None
                        category = None
                        
                        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –ø—Ä–æ–¥—É–∫—Ç–∞ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π
                        if 'Name' in df_param.columns:
                            product_name = df_param.loc[idx, 'Name']
                        elif 'Product Name' in df_param.columns:
                            product_name = df_param.loc[idx, 'Product Name']
                        elif 'product_name' in df_param.columns:
                            product_name = df_param.loc[idx, 'product_name']
                        
                        if 'Category' in df_param.columns:
                            category = df_param.loc[idx, 'Category']
                        elif 'category' in df_param.columns:
                            category = df_param.loc[idx, 'category']
                        elif 'group_name' in df_param.columns:
                            category = df_param.loc[idx, 'group_name']
                        
                        if use_ai_standardization:
                            standardized = standardize_value_intelligent_optimized(original, standardization_format, preview_col, product_name, category)
                        else:
                            standardized = standardize_value_simple_optimized(original, standardization_format, preview_col, product_name, category)
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                        context_info = []
                        if product_name:
                            context_info.append(f"–ü—Ä–æ–¥—É–∫—Ç: {str(product_name)[:30]}...")
                        if category:
                            context_info.append(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")
                        
                        context_str = " | ".join(context_info) if context_info else ""
                        
                        st.write(f"**–î–æ:** {original} ‚Üí **–ü–æ—Å–ª–µ:** {standardized}")
                        if context_str:
                            st.caption(f"üìù –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context_str}")
                
                # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
                standardization_button_text = "‚úÖ –ü—Ä–∏–º–µ–Ω–∏—Ç—å AI-—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é" if use_ai_standardization else "‚úÖ –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä–æ—Å—Ç—É—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é"
                
                if st.button(standardization_button_text, key="apply_standardization"):
                    standardized_df = df_param.copy()
                    
                    if use_ai_standardization:
                        with st.spinner("üß† AI-—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π..."):
                            progress_bar = st.progress(0)
                            
                            for i, column in enumerate(selected_columns):
                                progress_bar.progress((i + 1) / len(selected_columns))
                                
                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–∞–∫–µ—Ç–Ω—É—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é
                                new_column_name = f"{column}_ai_standardized"
                                standardized_df[new_column_name] = batch_standardize_column_optimized(
                                    standardized_df, 
                                    column, 
                                    standardization_format, 
                                    use_ai=True
                                )
                            
                            progress_bar.empty()
                            suffix = "ai_standardized"
                    else:
                        with st.spinner("‚ö° –ë—ã—Å—Ç—Ä–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π..."):
                            for column in selected_columns:
                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø–∞–∫–µ—Ç–Ω—É—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é
                                new_column_name = f"{column}_standardized"
                                standardized_df[new_column_name] = batch_standardize_column_optimized(
                                    standardized_df, 
                                    column, 
                                    standardization_format, 
                                    use_ai=False
                                )
                            suffix = "standardized"
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    st.session_state['df_standardization'] = standardized_df
                    method_name = "AI-—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è" if use_ai_standardization else "–ü—Ä–æ—Å—Ç–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è"
                    st.success(f"‚úÖ {method_name} –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –∫ {len(selected_columns)} –∫–æ–ª–æ–Ω–∫–∞–º!")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                    total_rows = len(standardized_df)
                    category_column = None
                    for col in ['group_name', 'Category', 'category']:
                        if col in standardized_df.columns:
                            category_column = col
                            break
                    
                    if category_column:
                        unique_categories = standardized_df[category_column].nunique()
                        st.info(f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏**: –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_rows} —Ç–æ–≤–∞—Ä–æ–≤ –≤ {unique_categories} –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö. –í–º–µ—Å—Ç–æ {total_rows * len(selected_columns)} –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –≤—Å–µ–≥–æ {unique_categories * len(selected_columns) * 5} –∞–Ω–∞–ª–∏–∑–æ–≤ –æ–±—Ä–∞–∑—Ü–æ–≤ (—ç–∫–æ–Ω–æ–º–∏—è ~{((total_rows * len(selected_columns) - unique_categories * len(selected_columns) * 5) / (total_rows * len(selected_columns)) * 100):.1f}%)")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    comparison_cols = []
                    for col in selected_columns:
                        new_col_name = f"{col}_{suffix}"
                        if new_col_name in standardized_df.columns:
                            comparison_cols.extend([col, new_col_name])
                    
                    if comparison_cols:
                        st.markdown("**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:**")
                        st.dataframe(standardized_df[comparison_cols].head(10))
        else:
            st.info("–°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–∏—Ç–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ä–∞–∑–¥–µ–ª–µ –≤—ã—à–µ.")

    # --- –≠—Ç–∞–ø 3: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è ---
    with st.expander("#### 3. üß† –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è", expanded=False):
        st.markdown("**AI-–∞–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –∏–∑–º–µ—Ä–µ–Ω–∏–π –∏ –µ–¥–∏–Ω–∏—Ü –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫**")
        
        if 'numeric_analysis_simple' in st.session_state and st.session_state['numeric_analysis_simple']:
            
            if st.button("üîç –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è (AI)", key="detect_units_ai"):
                measurement_analysis = {}
                
                progress_bar = st.progress(0)
                columns_to_analyze = list(st.session_state['numeric_analysis_simple'].keys())
                
                with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ–º AI-–∞–Ω–∞–ª–∏–∑ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è..."):
                    for i, column in enumerate(columns_to_analyze):
                        progress_bar.progress((i + 1) / len(columns_to_analyze))
                        
                        # –ë–µ—Ä–µ–º –æ–±—Ä–∞–∑–µ—Ü –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                        sample_values = df_param[column].dropna().head(max_samples).tolist()
                        analysis_result = detect_measurement_type_intelligent(column, sample_values)
                        
                        measurement_analysis[column] = {
                            'type': analysis_result['primary_dimension'],
                            'confidence': analysis_result['confidence'],
                            'common_units': analysis_result['common_units'],
                            'analysis_summary': analysis_result['analysis_summary'],
                            'sample_values': sample_values[:10]
                        }
                
                progress_bar.empty()
                st.session_state['measurement_analysis_ai'] = measurement_analysis
                st.success("‚úÖ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω!")
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–¥–∏–Ω–∏—Ü
            if 'measurement_analysis_ai' in st.session_state:
                st.markdown("**üß† –†–µ–∑—É–ª—å—Ç–∞—Ç—ã AI-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è**")
                
                measurement_data = []
                for column, analysis in st.session_state['measurement_analysis_ai'].items():
                    row = {
                        '–ö–æ–ª–æ–Ω–∫–∞': column,
                        '–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å': analysis['type'],
                        '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': f"{analysis['confidence']:.2f}",
                        '–ù–∞–π–¥–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã': ', '.join(analysis['common_units'][:5]),
                        '–ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π': ', '.join([str(v) for v in analysis['sample_values'][:3]])
                    }
                    measurement_data.append(row)
                
                measurement_df = pd.DataFrame(measurement_data)
                st.dataframe(measurement_df, use_container_width=True)
                
                # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                selected_column = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:",
                    options=list(st.session_state['measurement_analysis_ai'].keys())
                )
                
                if selected_column:
                    analysis = st.session_state['measurement_analysis_ai'][selected_column]
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏:**")
                        dimensions = analysis['analysis_summary']['dimensions_found']
                        for dim, count in dimensions.items():
                            st.write(f"- {dim}: {count}")
                    
                    with col2:
                        st.markdown("**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã:**")
                        units = analysis['analysis_summary']['units_found']
                        for unit, count in units.items():
                            st.write(f"- {unit}: {count}")
        else:
            st.info("–°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–∏—Ç–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ä–∞–∑–¥–µ–ª–µ –≤—ã—à–µ.")

    # --- –≠—Ç–∞–ø 4: –ü–∞–∫–µ—Ç–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü —Å Pint ---
    with st.expander("#### 4. üîÑ –ü–∞–∫–µ—Ç–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü (Pint)", expanded=False):
        if PINT_AVAILABLE and use_pint:
            st.markdown("**–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Å–µ—Ö –µ–¥–∏–Ω–∏—Ü –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç**")
            
            if 'measurement_analysis_ai' in st.session_state:
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
                conversion_options = {}
                
                for column, analysis in st.session_state['measurement_analysis_ai'].items():
                    dimension = analysis['type']
                    if dimension and dimension != 'unknown':
                        conversion_options[column] = {
                            'dimension': dimension,
                            'units': analysis['common_units']
                        }
                
                if conversion_options:
                    st.markdown("**–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏:**")
                    
                    for column, info in conversion_options.items():
                        st.write(f"**{column}** (—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {info['dimension']})")
                        st.write(f"–ù–∞–π–¥–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã: {', '.join(info['units'][:5])}")
                        
                        # –í—ã–±–æ—Ä —Ü–µ–ª–µ–≤–æ–π –µ–¥–∏–Ω–∏—Ü—ã
                        target_unit = st.text_input(
                            f"–¶–µ–ª–µ–≤–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –¥–ª—è {column}:",
                            value=info['units'][0] if info['units'] else '',
                            key=f"target_unit_{column}"
                        )
                        
                        conversion_options[column]['target_unit'] = target_unit
                    
                    if st.button("üîÑ –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–∞–∫–µ—Ç–Ω—É—é –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é", key="batch_conversion"):
                        # –ó–¥–µ—Å—å –±—É–¥–µ—Ç –ª–æ–≥–∏–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Å Pint
                        st.info("–§—É–Ω–∫—Ü–∏—è –ø–∞–∫–µ—Ç–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –≤ —Å–ª–µ–¥—É—é—â–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏")
                else:
                    st.info("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –µ–¥–∏–Ω–∏—Ü")
            else:
                st.info("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è")
        else:
            st.warning("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ Pint –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞ –∏–ª–∏ –Ω–µ –≤—ã–±—Ä–∞–Ω–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")

    # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
    with st.expander("#### 5. üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", expanded=False):
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        if 'df_standardization' in st.session_state:
            current_df = st.session_state['df_standardization']
            st.info(f"üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: {len(current_df)} —Å—Ç—Ä–æ–∫, {len(current_df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            simple_standardized_count = len([col for col in current_df.columns if col.endswith('_standardized') and not col.endswith('_ai_standardized')])
            ai_standardized_count = len([col for col in current_df.columns if '_ai_standardized' in col])
            
            if simple_standardized_count > 0:
                st.success(f"‚úÖ –ü—Ä–æ—Å—Ç—ã—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {simple_standardized_count}")
            if ai_standardized_count > 0:
                st.success(f"üß† AI-—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {ai_standardized_count}")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ grouped_categories.csv", key="save_main_ai"):
                try:
                    output_path = os.path.join(os.path.dirname(__file__), '..', 'grouped_categories.csv')
                    current_df = st.session_state.get('df_standardization', df_param)
                    current_df.to_csv(output_path, index=False, encoding='utf-8-sig')
                    st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
                    st.success(f"üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(current_df)} —Å—Ç—Ä–æ–∫, {len(current_df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
        
        with col2:
            if st.button("üì• –°–∫–∞—á–∞—Ç—å –∫–∞–∫ CSV", key="download_csv_ai"):
                current_df = st.session_state.get('df_standardization', df_param)
                csv_data = current_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª",
                    data=csv_data,
                    file_name="ai_standardized_parameters.csv",
                    mime="text/csv",
                    key="download_ai_standardized"
                )
        
        with col3:
            if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", key="reload_data_ai"):
                # –û—á–∏—â–∞–µ–º –∫—ç—à –∏ session state
                for key in ['df_standardization', 'numeric_analysis_simple', 'numeric_analysis_ai', 'measurement_analysis_ai']:
                    if key in st.session_state:
                        del st.session_state[key]
                
                # –û—á–∏—â–∞–µ–º –∫—ç—à —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤
                for func in [extract_numeric_values_intelligent, detect_measurement_type_intelligent, 
                           standardize_value_intelligent_optimized, analyze_column_statistics_intelligent]:
                    if hasattr(func, '_extractor'):
                        delattr(func, '_extractor')
                
                # –û—á–∏—â–∞–µ–º –∫—ç—à Streamlit
                st.cache_resource.clear()
                
                st.success("–î–∞–Ω–Ω—ã–µ –∏ –∫—ç—à –æ–±–Ω–æ–≤–ª–µ–Ω—ã! –°—Ç—Ä–∞–Ω–∏—Ü–∞ –±—É–¥–µ—Ç –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
                st.rerun()

    # --- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ---
    with st.expander("#### 6. üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤", expanded=False):
        current_df = st.session_state.get('df_standardization', df_param)
        total_cols = len(current_df.columns)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–ø—Ä–æ—Å—Ç—ã–µ + AI)
        simple_standardized_cols = len([col for col in current_df.columns if col.endswith('_standardized') and not col.endswith('_ai_standardized')])
        ai_standardized_cols = len([col for col in current_df.columns if '_ai_standardized' in col])
        total_standardized = simple_standardized_cols + ai_standardized_cols
        
        total_rows = len(current_df)
        
        stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
        with stat_col1:
            st.metric("–í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫", total_cols)
        with stat_col2:
            st.metric("–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö", total_standardized)
        with stat_col3:
            st.metric("–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", total_rows)
        with stat_col4:
            active_methods_count = sum([use_quantulum, use_transformers, use_pint])
            st.metric("–ê–∫—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –ò–ò", active_methods_count)
        
        # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —Ç–∏–ø–∞–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
        if total_standardized > 0:
            detail_col1, detail_col2 = st.columns(2)
            with detail_col1:
                st.metric("üîß –ü—Ä–æ—Å—Ç–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è", simple_standardized_cols)
            with detail_col2:
                st.metric("üß† AI-—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è", ai_standardized_cols)
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–µ—Ç–æ–¥–æ–≤
        simple_found = len(st.session_state.get('numeric_analysis_simple', {}))
        
        st.markdown("**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:**")
        st.write(f"- **–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑**: {simple_found} —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –Ω–∞–π–¥–µ–Ω–æ")
        
        if 'numeric_analysis_ai' in st.session_state:
            st.markdown("**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ò–ò-–º–µ—Ç–æ–¥–æ–≤:**")
            
            method_stats = {
                'Quantulum3': 0,
                'Transformers': 0,
                'Pint –≤–∞–ª–∏–¥–∞—Ü–∏—è': 0
            }
            
            for column, stats in st.session_state['numeric_analysis_ai'].items():
                extraction_stats = stats.get('extraction_stats', {})
                method_stats['Quantulum3'] += extraction_stats.get('quantulum_extractions', 0)
                method_stats['Transformers'] += extraction_stats.get('transformer_extractions', 0)
                method_stats['Pint –≤–∞–ª–∏–¥–∞—Ü–∏—è'] += extraction_stats.get('pint_validations', 0)
            
            for method, count in method_stats.items():
                st.write(f"- **{method}**: {count} —É—Å–ø–µ—à–Ω—ã—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏–π")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ", key="show_all_data_ai"):
            st.dataframe(current_df, use_container_width=True)
        else:
            st.markdown("**–ü–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫:**")
            st.dataframe(current_df.head(20), use_container_width=True)

else:
    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –≥–ª–∞–≤–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏.")
