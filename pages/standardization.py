import streamlit as st
import pandas as pd
import re
import os
import numpy as np
from collections import Counter

st.title("–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")

# –í—Å–µ–≥–¥–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–∑ grouped_categories.csv
csv_path = os.path.join(os.path.dirname(__file__), '..', 'grouped_categories.csv')
try:
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º session state –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π
    if 'df_standardization' not in st.session_state:
        st.session_state['df_standardization'] = pd.read_csv(csv_path, encoding='utf-8-sig')
    df_param = st.session_state['df_standardization']
    st.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ grouped_categories.csv ({len(df_param)} —Å—Ç—Ä–æ–∫, {len(df_param.columns)} –∫–æ–ª–æ–Ω–æ–∫)")
except Exception as e:
    df_param = pd.DataFrame()
    st.session_state['df_standardization'] = df_param
    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å grouped_categories.csv: {e}")

# --- –°–ª–æ–≤–∞—Ä–∏ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è ---
UNIT_PATTERNS = {
    # –ú–æ—â–Ω–æ—Å—Ç—å
    'power': {
        'patterns': [r'(\d+(?:\.\d+)?)\s*(kw|–∫–≤|–∫–≤—Ç|watt|w|–≤–∞—Ç—Ç|–≤—Ç)', 
                    r'(\d+(?:\.\d+)?)\s*(hp|–ª\.—Å|–ª—Å)', 
                    r'(\d+(?:\.\d+)?)\s*(mw|–º–≤—Ç)'],
        'units': ['kw', 'w', 'hp', 'mw'],
        'default_unit': 'w'
    },
    # –†–∞–∑–º–µ—Ä—ã
    'size': {
        'patterns': [r'(\d+(?:\.\d+)?)\s*(m|–º|meter|–º–µ—Ç—Ä)', 
                    r'(\d+(?:\.\d+)?)\s*(cm|—Å–º|—Å–∞–Ω—Ç–∏–º–µ—Ç—Ä)', 
                    r'(\d+(?:\.\d+)?)\s*(mm|–º–º|–º–∏–ª–ª–∏–º–µ—Ç—Ä)',
                    r'(\d+(?:\.\d+)?)\s*(km|–∫–º|–∫–∏–ª–æ–º–µ—Ç—Ä)',
                    r'(\d+(?:\.\d+)?)\s*(inch|–¥—é–π–º|"|\')',
                    r'(\d+(?:\.\d+)?)\s*(ft|—Ñ—É—Ç)'],
        'units': ['m', 'cm', 'mm', 'km', 'inch', 'ft'],
        'default_unit': 'cm'
    },
    # –í–µ—Å
    'weight': {
        'patterns': [r'(\d+(?:\.\d+)?)\s*(kg|–∫–≥|–∫–∏–ª–æ–≥—Ä–∞–º–º)', 
                    r'(\d+(?:\.\d+)?)\s*(g|–≥|–≥—Ä–∞–º–º)', 
                    r'(\d+(?:\.\d+)?)\s*(t|—Ç|—Ç–æ–Ω–Ω)',
                    r'(\d+(?:\.\d+)?)\s*(lb|—Ñ—É–Ω—Ç)',
                    r'(\d+(?:\.\d+)?)\s*(oz|—É–Ω—Ü–∏—è)'],
        'units': ['kg', 'g', 't', 'lb', 'oz'],
        'default_unit': 'kg'
    },
    # –û–±—ä–µ–º
    'volume': {
        'patterns': [r'(\d+(?:\.\d+)?)\s*(l|–ª|–ª–∏—Ç—Ä)', 
                    r'(\d+(?:\.\d+)?)\s*(ml|–º–ª|–º–∏–ª–ª–∏–ª–∏—Ç—Ä)', 
                    r'(\d+(?:\.\d+)?)\s*(m3|–º3|–∫—É–±)',
                    r'(\d+(?:\.\d+)?)\s*(gallon|–≥–∞–ª–ª–æ–Ω)'],
        'units': ['l', 'ml', 'm3', 'gallon'],
        'default_unit': 'l'
    },
    # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
    'temperature': {
        'patterns': [r'(\d+(?:\.\d+)?)\s*(¬∞c|c|—Ü–µ–ª—å—Å–∏)', 
                    r'(\d+(?:\.\d+)?)\s*(¬∞f|f|—Ñ–∞—Ä–µ–Ω–≥–µ–π—Ç)', 
                    r'(\d+(?:\.\d+)?)\s*(k|–∫–µ–ª—å–≤–∏–Ω)'],
        'units': ['¬∞c', '¬∞f', 'k'],
        'default_unit': '¬∞c'
    },
    # –í—Ä–µ–º—è
    'time': {
        'patterns': [r'(\d+(?:\.\d+)?)\s*(sec|—Å|—Å–µ–∫—É–Ω–¥)', 
                    r'(\d+(?:\.\d+)?)\s*(min|–º|–º–∏–Ω—É—Ç)', 
                    r'(\d+(?:\.\d+)?)\s*(h|—á|—á–∞—Å)',
                    r'(\d+(?:\.\d+)?)\s*(day|–¥|–¥–µ–Ω—å|–¥–Ω–µ–π)',
                    r'(\d+(?:\.\d+)?)\s*(year|–≥|–≥–æ–¥|–ª–µ—Ç)'],
        'units': ['sec', 'min', 'h', 'day', 'year'],
        'default_unit': 'h'
    }
}

# --- –§—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ ---

def extract_numeric_values(text):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    if pd.isna(text):
        return []
    
    # –ò—â–µ–º —á–∏—Å–ª–∞ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è
    numeric_pattern = r'(\d+(?:\.\d+)?(?:,\d+)?)\s*([a-zA-Z–∞-—è—ë¬∞"\'\s]+)?'
    matches = re.findall(numeric_pattern, str(text), re.IGNORECASE)
    
    results = []
    for match in matches:
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —á–∏—Å–ª–æ (–∑–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É)
            number = float(match[0].replace(',', '.'))
            unit = match[1].strip() if match[1] else ''
            results.append((number, unit))
        except ValueError:
            continue
    
    return results

def detect_measurement_type(column_name, values_sample):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∏–∑–º–µ—Ä–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–∫–∏ –∏ –ø—Ä–∏–º–µ—Ä–æ–≤ –∑–Ω–∞—á–µ–Ω–∏–π"""
    column_lower = column_name.lower()
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
    type_keywords = {
        'power': ['power', '–º–æ—â–Ω–æ—Å—Ç—å', 'watt', '–≤–∞—Ç—Ç', 'kw', '–∫–≤—Ç'],
        'size': ['size', 'length', 'width', 'height', 'dimension', '—Ä–∞–∑–º–µ—Ä', '–¥–ª–∏–Ω–∞', '—à–∏—Ä–∏–Ω–∞', '–≤—ã—Å–æ—Ç–∞', '–¥–∏–∞–º–µ—Ç—Ä'],
        'weight': ['weight', 'mass', '–≤–µ—Å', '–º–∞—Å—Å–∞', 'kg', '–∫–≥'],
        'volume': ['volume', 'capacity', '–æ–±—ä–µ–º', '–µ–º–∫–æ—Å—Ç—å', '–ª–∏—Ç—Ä', 'liter'],
        'temperature': ['temp', 'temperature', '—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞', '–≥—Ä–∞–¥—É—Å'],
        'time': ['time', 'duration', '–≤—Ä–µ–º—è', '–ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å', '—á–∞—Å', '–º–∏–Ω—É—Ç']
    }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
    for measurement_type, keywords in type_keywords.items():
        for keyword in keywords:
            if keyword in column_lower:
                return measurement_type
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
    unit_counts = Counter()
    for value in values_sample:
        if pd.notna(value):
            for measurement_type, config in UNIT_PATTERNS.items():
                for pattern in config['patterns']:
                    if re.search(pattern, str(value), re.IGNORECASE):
                        unit_counts[measurement_type] += 1
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π —Ç–∏–ø
    if unit_counts:
        return unit_counts.most_common(1)[0][0]
    
    return 'unknown'

def extract_unit_from_value(value, measurement_type):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏–∑ –∑–Ω–∞—á–µ–Ω–∏—è"""
    if pd.isna(value) or measurement_type == 'unknown':
        return None
    
    config = UNIT_PATTERNS.get(measurement_type, {})
    patterns = config.get('patterns', [])
    
    for pattern in patterns:
        match = re.search(pattern, str(value), re.IGNORECASE)
        if match:
            return match.group(2).lower()
    
    return None

def standardize_value(value, measurement_type, target_unit=None):
    """–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Å –µ–¥–∏–Ω–∏—Ü–µ–π –∏–∑–º–µ—Ä–µ–Ω–∏—è"""
    if pd.isna(value):
        return value
    
    numeric_values = extract_numeric_values(value)
    if not numeric_values:
        return value
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    number, unit = numeric_values[0]
    
    if measurement_type == 'unknown':
        return value
    
    config = UNIT_PATTERNS.get(measurement_type, {})
    default_unit = target_unit or config.get('default_unit', '')
    
    # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞, –¥–æ–±–∞–≤–ª—è–µ–º –µ–¥–∏–Ω–∏—Ü—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if not unit:
        detected_unit = extract_unit_from_value(value, measurement_type)
        if detected_unit:
            unit = detected_unit
        else:
            unit = default_unit
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    if unit:
        return f"{number} {unit}"
    else:
        return str(number)

def analyze_column_statistics(df, column):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–ª–æ–Ω–∫–∏"""
    values = df[column].dropna()
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_values = len(values)
    numeric_values = []
    units_found = Counter()
    
    for value in values:
        nums = extract_numeric_values(value)
        for num, unit in nums:
            numeric_values.append(num)
            if unit:
                units_found[unit.lower()] += 1
    
    stats = {
        'total_values': total_values,
        'numeric_count': len(numeric_values),
        'units_found': dict(units_found.most_common(10)),
        'numeric_stats': {}
    }
    
    if numeric_values:
        stats['numeric_stats'] = {
            'min': min(numeric_values),
            'max': max(numeric_values),
            'mean': sum(numeric_values) / len(numeric_values),
            'count': len(numeric_values)
        }
    
    return stats

# --- –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---

if not df_param.empty:
    st.dataframe(df_param.head(20))
    all_columns = list(df_param.columns)

    # –ò—Å–∫–ª—é—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    system_columns = [
        col for col in all_columns
        if any(keyword in col.lower() for keyword in ['name', 'id', 'source_file', 'category'])
    ]

    st.markdown("#### –ò—Å–∫–ª—é—á–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞")
    excluded_cols = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å:",
        options=all_columns,
        default=system_columns
    )

    analysis_columns = [c for c in all_columns if c not in excluded_cols]
    
    # --- –≠—Ç–∞–ø 1: –ê–Ω–∞–ª–∏–∑ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π ---
    with st.expander("#### 1. üîç –ê–Ω–∞–ª–∏–∑ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö", expanded=True):
        st.markdown("**–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏**")
        
        if st.button("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", key="analyze_numeric"):
            if not analysis_columns:
                st.warning("–ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è.")
            else:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –∫–æ–ª–æ–Ω–∫—É
                numeric_analysis = {}
                
                progress_bar = st.progress(0)
                for i, column in enumerate(analysis_columns):
                    progress_bar.progress((i + 1) / len(analysis_columns))
                    
                    stats = analyze_column_statistics(df_param, column)
                    if stats['numeric_count'] > 0:
                        numeric_analysis[column] = stats
                
                progress_bar.empty()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                st.session_state['numeric_analysis'] = numeric_analysis
                
                if numeric_analysis:
                    st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(numeric_analysis)} –∫–æ–ª–æ–Ω–æ–∫ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏!")
                else:
                    st.info("–ö–æ–ª–æ–Ω–∫–∏ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        if 'numeric_analysis' in st.session_state and st.session_state['numeric_analysis']:
            st.markdown("**üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π**")
            
            analysis_data = []
            for column, stats in st.session_state['numeric_analysis'].items():
                row = {
                    '–ö–æ–ª–æ–Ω–∫–∞': column,
                    '–í—Å–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–π': stats['total_values'],
                    '–ß–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π': stats['numeric_count'],
                    '% —á–∏—Å–ª–æ–≤—ã—Ö': f"{(stats['numeric_count'] / stats['total_values'] * 100):.1f}%",
                    '–ú–∏–Ω': stats['numeric_stats'].get('min', 0),
                    '–ú–∞–∫—Å': stats['numeric_stats'].get('max', 0),
                    '–°—Ä–µ–¥–Ω–µ–µ': f"{stats['numeric_stats'].get('mean', 0):.2f}",
                    '–ï–¥–∏–Ω–∏—Ü—ã': ', '.join(list(stats['units_found'].keys())[:3])
                }
                analysis_data.append(row)
            
            analysis_df = pd.DataFrame(analysis_data)
            st.dataframe(analysis_df, use_container_width=True)

    # --- –≠—Ç–∞–ø 2: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è ---
    with st.expander("#### 2. üìè –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è", expanded=False):
        st.markdown("**–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∏–∑–º–µ—Ä–µ–Ω–∏–π**")
        
        if 'numeric_analysis' in st.session_state and st.session_state['numeric_analysis']:
            
            if st.button("üîç –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è", key="detect_units"):
                measurement_analysis = {}
                
                for column in st.session_state['numeric_analysis'].keys():
                    # –ë–µ—Ä–µ–º –æ–±—Ä–∞–∑–µ—Ü –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    sample_values = df_param[column].dropna().head(50).tolist()
                    measurement_type = detect_measurement_type(column, sample_values)
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –µ–¥–∏–Ω–∏—Ü—ã –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö
                    detected_units = Counter()
                    for value in sample_values:
                        unit = extract_unit_from_value(value, measurement_type)
                        if unit:
                            detected_units[unit] += 1
                    
                    measurement_analysis[column] = {
                        'type': measurement_type,
                        'detected_units': dict(detected_units.most_common(5)),
                        'sample_values': sample_values[:10]
                    }
                
                st.session_state['measurement_analysis'] = measurement_analysis
                st.success("–ê–Ω–∞–ª–∏–∑ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω!")
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–¥–∏–Ω–∏—Ü
            if 'measurement_analysis' in st.session_state:
                st.markdown("**üìè –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è**")
                
                measurement_data = []
                for column, analysis in st.session_state['measurement_analysis'].items():
                    row = {
                        '–ö–æ–ª–æ–Ω–∫–∞': column,
                        '–¢–∏–ø –∏–∑–º–µ—Ä–µ–Ω–∏—è': analysis['type'],
                        '–ù–∞–π–¥–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã': ', '.join(analysis['detected_units'].keys()),
                        '–ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π': ', '.join([str(v) for v in analysis['sample_values'][:3]])
                    }
                    measurement_data.append(row)
                
                measurement_df = pd.DataFrame(measurement_data)
                st.dataframe(measurement_df, use_container_width=True)
        else:
            st.info("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Ä–∞–∑–¥–µ–ª–µ –≤—ã—à–µ.")

    # --- –≠—Ç–∞–ø 3: –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π ---
    with st.expander("#### 3. ‚öôÔ∏è –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π", expanded=False):
        st.markdown("**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è**")
        
        if 'measurement_analysis' in st.session_state:
            
            # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
            standardizable_columns = list(st.session_state['measurement_analysis'].keys())
            selected_columns = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏:",
                options=standardizable_columns,
                default=standardizable_columns
            )
            
            if selected_columns:
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–∏
                st.markdown("**–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏:**")
                standardization_config = {}
                
                for column in selected_columns:
                    analysis = st.session_state['measurement_analysis'][column]
                    measurement_type = analysis['type']
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**{column}** (—Ç–∏–ø: {measurement_type})")
                    
                    with col2:
                        if measurement_type in UNIT_PATTERNS:
                            available_units = UNIT_PATTERNS[measurement_type]['units']
                            default_unit = UNIT_PATTERNS[measurement_type]['default_unit']
                            
                            target_unit = st.selectbox(
                                f"–¶–µ–ª–µ–≤–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –¥–ª—è {column}:",
                                options=available_units,
                                index=available_units.index(default_unit) if default_unit in available_units else 0,
                                key=f"unit_{column}"
                            )
                            
                            standardization_config[column] = {
                                'type': measurement_type,
                                'target_unit': target_unit
                            }
                
                # –ö–Ω–æ–ø–∫–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
                if st.button("‚úÖ –ü—Ä–∏–º–µ–Ω–∏—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é", key="apply_standardization"):
                    standardized_df = df_param.copy()
                    
                    for column, config in standardization_config.items():
                        measurement_type = config['type']
                        target_unit = config['target_unit']
                        
                        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                        new_column_name = f"{column}_standardized"
                        standardized_df[new_column_name] = standardized_df[column].apply(
                            lambda x: standardize_value(x, measurement_type, target_unit)
                        )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    st.session_state['df_standardization'] = standardized_df
                    st.success("–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∞!")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
                    standardized_cols = [col for col in standardized_df.columns if '_standardized' in col]
                    if standardized_cols:
                        st.markdown("**–ü—Ä–∏–º–µ—Ä—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π:**")
                        comparison_cols = []
                        for col in standardized_cols:
                            original_col = col.replace('_standardized', '')
                            if original_col in standardized_df.columns:
                                comparison_cols.extend([original_col, col])
                        
                        if comparison_cols:
                            st.dataframe(standardized_df[comparison_cols].head(10))
        else:
            st.info("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤ —Ä–∞–∑–¥–µ–ª–µ –≤—ã—à–µ.")

    # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
    with st.expander("#### 4. üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", expanded=False):
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        if 'df_standardization' in st.session_state:
            current_df = st.session_state['df_standardization']
            st.info(f"üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: {len(current_df)} —Å—Ç—Ä–æ–∫, {len(current_df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            standardized_count = len([col for col in current_df.columns if '_standardized' in col])
            if standardized_count > 0:
                st.success(f"‚úÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {standardized_count}")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ grouped_categories.csv", key="save_main_std"):
                try:
                    output_path = os.path.join(os.path.dirname(__file__), '..', 'grouped_categories.csv')
                    current_df = st.session_state.get('df_standardization', df_param)
                    current_df.to_csv(output_path, index=False, encoding='utf-8-sig')
                    st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
                    st.success(f"üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(current_df)} —Å—Ç—Ä–æ–∫, {len(current_df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
        
        with col2:
            if st.button("üì• –°–∫–∞—á–∞—Ç—å –∫–∞–∫ CSV", key="download_csv_std"):
                current_df = st.session_state.get('df_standardization', df_param)
                csv_data = current_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª",
                    data=csv_data,
                    file_name="standardized_parameters.csv",
                    mime="text/csv",
                    key="download_standardized"
                )
        
        with col3:
            if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", key="reload_data_std"):
                # –û—á–∏—â–∞–µ–º –∫—ç—à –∏ session state
                for key in ['df_standardization', 'numeric_analysis', 'measurement_analysis']:
                    if key in st.session_state:
                        del st.session_state[key]
                st.success("–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã! –°—Ç—Ä–∞–Ω–∏—Ü–∞ –±—É–¥–µ—Ç –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
                st.rerun()

    # --- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ---
    with st.expander("#### 5. üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º", expanded=False):
        current_df = st.session_state.get('df_standardization', df_param)
        total_cols = len(current_df.columns)
        standardized_cols = len([col for col in current_df.columns if '_standardized' in col])
        total_rows = len(current_df)
        
        stat_col1, stat_col2, stat_col3 = st.columns(3)
        with stat_col1:
            st.metric("–í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫", total_cols)
        with stat_col2:
            st.metric("–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫", standardized_cols)
        with stat_col3:
            st.metric("–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", total_rows)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ", key="show_all_data_std"):
            st.dataframe(current_df, use_container_width=True)
        else:
            st.markdown("**–ü–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫:**")
            st.dataframe(current_df.head(20), use_container_width=True)

else:
    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –≥–ª–∞–≤–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏.")
