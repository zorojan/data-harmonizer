import streamlit as st
import pandas as pd
import re
import os
import numpy as np
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è
try:
    import quantulum3
    QUANTULUM_AVAILABLE = True
except ImportError:
    QUANTULUM_AVAILABLE = False

try:
    import pint
    ureg = pint.UnitRegistry()
    PINT_AVAILABLE = True
except ImportError:
    PINT_AVAILABLE = False

try:
    from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

st.title("üî¨ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")

# –í—Å–µ–≥–¥–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–∑ grouped_categories.csv
csv_path = os.path.join(os.path.dirname(__file__), '..', 'grouped_categories.csv')
try:
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º session state –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π
    if 'df_standardization' not in st.session_state:
        st.session_state['df_standardization'] = pd.read_csv(csv_path, encoding='utf-8-sig')
    df_param = st.session_state['df_standardization']
    st.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ grouped_categories.csv ({len(df_param)} —Å—Ç—Ä–æ–∫, {len(df_param.columns)} –∫–æ–ª–æ–Ω–æ–∫)")
except Exception as e:
    df_param = pd.DataFrame()
    st.session_state['df_standardization'] = df_param
    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å grouped_categories.csv: {e}")

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–µ—Ç–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ ---
st.sidebar.markdown("## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–µ—Ç–æ–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞")

# –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è
st.sidebar.markdown("### üìè –ú–µ—Ç–æ–¥—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –µ–¥–∏–Ω–∏—Ü:")

use_quantulum = st.sidebar.checkbox(
    "üîç Quantulum3 (—Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –≤–µ–ª–∏—á–∏–Ω—ã)", 
    value=QUANTULUM_AVAILABLE,
    disabled=not QUANTULUM_AVAILABLE,
    help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –≤–µ–ª–∏—á–∏–Ω –∏ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞"
)

use_transformers = st.sidebar.checkbox(
    "ü§ñ Transformer-NER (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑)", 
    value=False,
    disabled=not TRANSFORMERS_AVAILABLE,
    help="–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π –∏ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è"
)

use_pint = st.sidebar.checkbox(
    "üìê Pint (–≤–∞–ª–∏–¥–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü)", 
    value=PINT_AVAILABLE,
    disabled=not PINT_AVAILABLE,
    help="–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è"
)

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
st.sidebar.markdown("### üéØ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
confidence_threshold = st.sidebar.slider(
    "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è", 
    min_value=0.1, 
    max_value=1.0, 
    value=0.7,
    help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"
)

max_samples = st.sidebar.number_input(
    "–ú–∞–∫—Å–∏–º—É–º –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", 
    min_value=5, 
    max_value=100, 
    value=20,
    help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–µ"
)

# –°—Ç–∞—Ç—É—Å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫
st.sidebar.markdown("### üìö –°—Ç–∞—Ç—É—Å –±–∏–±–ª–∏–æ—Ç–µ–∫:")
st.sidebar.success(f"‚úÖ Quantulum3: {'–î–æ—Å—Ç—É–ø–Ω–∞' if QUANTULUM_AVAILABLE else '–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'}")
st.sidebar.success(f"‚úÖ Transformers: {'–î–æ—Å—Ç—É–ø–Ω–∞' if TRANSFORMERS_AVAILABLE else '–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'}")
st.sidebar.success(f"‚úÖ Pint: {'–î–æ—Å—Ç—É–ø–Ω–∞' if PINT_AVAILABLE else '–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞'}")

# --- –ü—Ä–æ—Å—Ç—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ ---

def analyze_column_statistics_simple(df, column):
    """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
    values = df[column].dropna()
    
    # –ü—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–∏—Ñ—Ä
    numeric_pattern = r'\d+\.?\d*'
    unit_pattern = r'(\d+\.?\d*)\s*([a-zA-Z–∞-—è—ë¬∞"\'\s]*)'
    
    numeric_count = 0
    units_found = Counter()
    numeric_values = []
    
    # –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –æ–±—Ä–∞–∑—Ü–∞ (–º–∞–∫—Å–∏–º—É–º 50 –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
    sample_size = min(50, len(values))
    
    for value in values.head(sample_size):
        if pd.isna(value):
            continue
            
        value_str = str(value).strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ü–∏—Ñ—Ä
        if re.search(numeric_pattern, value_str):
            numeric_count += 1
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–∞ –∏ –µ–¥–∏–Ω–∏—Ü—ã –ø—Ä–æ—Å—Ç—ã–º —Å–ø–æ—Å–æ–±–æ–º
            matches = re.findall(unit_pattern, value_str)
            for number, unit in matches:
                try:
                    numeric_values.append(float(number))
                    unit_clean = unit.strip()
                    # –ù–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä: –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º 'x', '-', ':', '' –∏ –Ω–µ–∞–ª—Ñ–∞–≤–∏—Ç–Ω—ã–µ "–µ–¥–∏–Ω–∏—Ü—ã"
                    if (
                        unit_clean
                        and len(unit_clean) < 15
                        and unit_clean.lower() not in ['x', '-', ':', '']
                        and re.search(r'[a-zA-Z–∞-—è—ë]', unit_clean)
                    ):
                        units_found[unit_clean] += 1
                except:
                    continue
    
    # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç "—á–∏—Å–ª–æ–≤–æ—Å—Ç–∏"
    numeric_percentage = (numeric_count / sample_size * 100) if sample_size > 0 else 0
    
    return {
        'total_values': len(values),
        'analyzed_values': sample_size,
        'numeric_count': numeric_count,
        'numeric_percentage': numeric_percentage,
        'units_found': dict(units_found.most_common(5)),
        'has_numeric': numeric_percentage > 20,  # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–æ–Ω–∫—É —á–∏—Å–ª–æ–≤–æ–π –µ—Å–ª–∏ >20% —Å–æ–¥–µ—Ä–∂–∞—Ç —Ü–∏—Ñ—Ä—ã
        'numeric_values': numeric_values[:10],  # –ü–µ—Ä–≤—ã–µ 10 —á–∏—Å–µ–ª –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
        'avg_value': sum(numeric_values) / len(numeric_values) if numeric_values else 0
    }

def quick_find_numeric_columns(df, columns_to_analyze):
    """–ë—ã—Å—Ç—Ä–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫"""
    numeric_columns = {}
    
    for column in columns_to_analyze:
        stats = analyze_column_statistics_simple(df, column)
        if stats['has_numeric']:
            numeric_columns[column] = stats
    
    return numeric_columns

def standardize_value_simple(value, target_format='number_unit', column_name=None, product_name=None, category=None):
    """–ü—Ä–æ—Å—Ç–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è"""
    if pd.isna(value):
        return value
    
    value_str = str(value).strip()
    
    # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω: —á–∏—Å–ª–æ + –µ–¥–∏–Ω–∏—Ü–∞
    pattern = r'(\d+\.?\d*)\s*([a-zA-Z–∞-—è—ë¬∞"\'\s]*)'
    match = re.search(pattern, value_str)
    
    if match:
        number = match.group(1)
        unit = match.group(2).strip()
        
        # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ –ø—É—Å—Ç–∞—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ª–æ–≥–∏–∫—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–¥–∏–Ω–∏—Ü
        if not unit and column_name:
            unit_from_context = extract_unit_from_context_optimized(column_name, product_name, category)
            if unit_from_context:
                unit = unit_from_context
        
        # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ –≤—Å–µ –µ—â–µ –ø—É—Å—Ç–∞—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not unit:
            return value
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
        if target_format == 'number_unit':
            return f"{number} {unit}"
        elif target_format == 'unit_number':
            return f"{unit} {number}"
        else:
            return f"{number} {unit}"
    
    return value

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä (—Å–∏–Ω–≥–ª—Ç–æ–Ω) ---
@st.cache_resource
def get_transformer_pipeline():
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Transformer-NER –º–æ–¥–µ–ª–∏"""
    if not TRANSFORMERS_AVAILABLE:
        return None
    
    try:
        return pipeline(
            "ner", 
            model="dbmdz/bert-large-cased-finetuned-conll03-english",
            aggregation_strategy="simple"
        )
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å Transformer –º–æ–¥–µ–ª—å: {e}")
        return None

# --- –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ ---

class IntelligentUnitExtractor:
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è"""
    def __init__(self, use_quantulum=True, use_transformers=True, use_pint=True):
        self._use_quantulum = use_quantulum
        self._use_transformers = use_transformers
        self._use_pint = use_pint
        self.transformer_pipeline = get_transformer_pipeline() if self._use_transformers else None

    def extract_with_quantulum(self, text):
        if not QUANTULUM_AVAILABLE or not self._use_quantulum:
            return []
        try:
            parsed = quantulum3.parser.parse(str(text))
            results = []
            for quantity in parsed:
                if quantity.value and quantity.unit:
                    unit_name = quantity.unit.name
                    unit_symbol = getattr(quantity.unit, 'symbol', unit_name)
                    pint_validation = self.validate_with_pint(unit_symbol)
                    if pint_validation and pint_validation.get('is_valid'):
                        canonical_unit = pint_validation.get('canonical_unit', unit_symbol)
                        dimension = pint_validation.get('dimensionality', quantity.unit.dimension.name if quantity.unit.dimension else '')
                        confidence = 0.95
                    else:
                        canonical_unit = unit_symbol
                        dimension = quantity.unit.dimension.name if quantity.unit.dimension else ''
                        confidence = 0.8
                    results.append({
                        'value': quantity.value,
                        'unit': canonical_unit,
                        'unit_symbol': canonical_unit,
                        'dimension': dimension,
                        'confidence': confidence,
                        'method': 'quantulum3_pint' if pint_validation and pint_validation.get('is_valid') else 'quantulum3',
                        'pint_validation': pint_validation
                    })
            return results
        except Exception:
            return []

    def extract_with_transformers(self, text):
        if not TRANSFORMERS_AVAILABLE or not self._use_transformers or not self.transformer_pipeline:
            return []
        try:
            pattern = r"(\d+(?:\.\d+)?)\s*([a-zA-Z–∞-—è—ë¬∞'\"\s]+)"
            matches = re.findall(pattern, str(text).lower())
            results = []
            for value, unit in matches:
                try:
                    numeric_value = float(value)
                    unit_clean = unit.strip()
                    if len(unit_clean) > 0 and len(unit_clean) < 20:
                        pint_validation = self.validate_with_pint(unit_clean)
                        if pint_validation and pint_validation.get('is_valid'):
                            confidence = 0.9 if pint_validation.get('method') == 'pint_exact' else 0.7
                            canonical_unit = pint_validation.get('canonical_unit', unit_clean)
                            results.append({
                                'value': numeric_value,
                                'unit': canonical_unit,
                                'unit_symbol': canonical_unit,
                                'dimension': pint_validation.get('dimensionality', 'unknown'),
                                'confidence': confidence,
                                'method': 'transformers_pint',
                                'pint_validation': pint_validation
                            })
                        else:
                            results.append({
                                'value': numeric_value,
                                'unit': unit_clean,
                                'unit_symbol': unit_clean,
                                'dimension': 'unknown',
                                'confidence': 0.4,
                                'method': 'transformers_only'
                            })
                except ValueError:
                    continue
            return results
        except Exception:
            return []

    def validate_with_pint(self, unit_string):
        if not PINT_AVAILABLE or not self._use_pint:
            return None
        try:
            unit_clean = re.sub(r'[^\w¬∞]', '', str(unit_string).strip())
            try:
                unit = ureg.parse_expression(unit_clean)
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–æ–ª—É—á–∞–µ–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
                dimensionality_str = str(unit.dimensionality)
                
                # –£–ª—É—á—à–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                if dimensionality_str == '[mass] * [length] ** 2 / [time] ** 3':
                    dimension_name = 'power'
                elif dimensionality_str == '[mass] * [length] ** 2 / [time] ** 2':
                    dimension_name = 'energy'
                elif dimensionality_str == '[length]':
                    dimension_name = 'length'
                elif dimensionality_str == '[mass]':
                    dimension_name = 'mass'
                elif dimensionality_str == '[time]':
                    dimension_name = 'time'
                elif dimensionality_str == '' or dimensionality_str == '1':
                    dimension_name = 'dimensionless'
                else:
                    dimension_name = dimensionality_str
                
                return {
                    'unit_str': str(unit),
                    'dimensionality': dimension_name,  # –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                    'is_valid': True,
                    'canonical_unit': str(unit.units),  # –ë–ï–ó to_base_units()!
                    'method': 'pint_exact'
                }
            except:
                pass
            try:
                for unit_name in ureg._units.keys():
                    if unit_clean.lower() in str(unit_name).lower() or str(unit_name).lower() in unit_clean.lower():
                        unit = ureg.parse_expression(unit_name)
                        
                        # –¢–∞ –∂–µ –ª–æ–≥–∏–∫–∞ –¥–ª—è fuzzy –ø–æ–∏—Å–∫–∞
                        dimensionality_str = str(unit.dimensionality)
                        if dimensionality_str == '[mass] * [length] ** 2 / [time] ** 3':
                            dimension_name = 'power'
                        elif dimensionality_str == '[mass] * [length] ** 2 / [time] ** 2':
                            dimension_name = 'energy'
                        elif dimensionality_str == '[length]':
                            dimension_name = 'length'
                        elif dimensionality_str == '[mass]':
                            dimension_name = 'mass'
                        elif dimensionality_str == '[time]':
                            dimension_name = 'time'
                        elif dimensionality_str == '' or dimensionality_str == '1':
                            dimension_name = 'dimensionless'
                        else:
                            dimension_name = dimensionality_str
                        
                        return {
                            'unit_str': str(unit),
                            'dimensionality': dimension_name,  # –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                            'is_valid': True,
                            'canonical_unit': str(unit.units),  # –ë–ï–ó to_base_units()!
                            'method': 'pint_fuzzy',
                            'original_input': unit_clean,
                            'matched_unit': unit_name
                        }
            except:
                pass
            return {'is_valid': False, 'method': 'pint', 'error': 'No match found'}
        except Exception as e:
            return {'is_valid': False, 'method': 'pint', 'error': str(e)}

    def extract_all_methods(self, text):
        all_results = []
        all_results.extend(self.extract_with_quantulum(text))
        all_results.extend(self.extract_with_transformers(text))
        for result in all_results:
            pint_validation = self.validate_with_pint(result['unit'])
            if pint_validation:
                result['pint_validation'] = pint_validation
        return all_results

def extract_numeric_values_intelligent(text):
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
    if pd.isna(text):
        return []
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    if not hasattr(extract_numeric_values_intelligent, '_extractor'):
        extract_numeric_values_intelligent._extractor = IntelligentUnitExtractor()
    
    extractor = extract_numeric_values_intelligent._extractor
    
    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤
    results = extractor.extract_all_methods(text)
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    filtered_results = [r for r in results if r.get('confidence', 0) >= confidence_threshold]
    
    return filtered_results

def detect_measurement_type_intelligent(column_name, values_sample, use_quantulum=None, use_transformers=None, use_pint=None):
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫–æ–ª–æ–Ω–∫–∏
    use_quantulum/use_transformers/use_pint: –µ—Å–ª–∏ None ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –µ—Å–ª–∏ True/False ‚Äî —Ñ–æ—Ä—Å–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∂–∏–º"""
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ –º–µ—Ç–æ–¥—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
    uq = use_quantulum if use_quantulum is not None else globals().get('use_quantulum', True)
    ut = use_transformers if use_transformers is not None else globals().get('use_transformers', True)
    up = use_pint if use_pint is not None else globals().get('use_pint', True)
    extractor = IntelligentUnitExtractor(use_quantulum=uq, use_transformers=ut, use_pint=up)
    dimension_counter = Counter()
    unit_counter = Counter()
    context_unit = extract_unit_from_context_optimized(column_name, None, None)
    if context_unit:
        pint_validation = extractor.validate_with_pint(context_unit)
        if pint_validation and pint_validation.get('is_valid'):
            dimension = pint_validation.get('dimensionality', 'unknown')
            canonical_unit = pint_validation.get('canonical_unit', context_unit)
            dimension_counter[dimension] = len(values_sample)
            unit_counter[canonical_unit] = len(values_sample)
            numeric_count = 0
            for value in values_sample[:max_samples]:
                if pd.notna(value):
                    value_str = str(value).strip()
                    if re.search(r'\d+\.?\d*', value_str):
                        numeric_count += 1
            if numeric_count / len(values_sample) > 0.5:
                return {
                    'primary_dimension': dimension,
                    'confidence': 0.95,  # –ü–û–í–´–®–ï–ù–ù–ê–Ø —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    'common_units': [canonical_unit],
                    'analysis_summary': {
                        'dimensions_found': {dimension: len(values_sample)},
                        'units_found': {canonical_unit: len(values_sample)},
                        'context_unit': context_unit,
                        'method': 'context_analysis_priority'  # –£–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –º–µ—Ç–æ–¥
                    }
                }
    for value in values_sample[:max_samples]:
        if pd.notna(value):
            extractions = extractor.extract_all_methods(value)
            for extraction in extractions:
                if extraction.get('confidence', 0) >= confidence_threshold:
                    dimension = extraction.get('dimension', 'unknown')
                    if dimension and dimension != 'unknown':
                        dimension_counter[dimension] += 1
                    unit = extraction.get('unit', '')
                    if unit:
                        unit_counter[unit] += 1
                    pint_val = extraction.get('pint_validation', {})
                    if pint_val.get('is_valid'):
                        pint_dimension = pint_val.get('dimensionality', '')
                        if pint_dimension:
                            dimension_counter[pint_dimension] += 2
    most_common_dimension = dimension_counter.most_common(1)
    most_common_unit = unit_counter.most_common(3)
    return {
        'primary_dimension': most_common_dimension[0][0] if most_common_dimension else 'unknown',
        'confidence': most_common_dimension[0][1] / len(values_sample) if most_common_dimension else 0,
        'common_units': [unit for unit, count in most_common_unit],
        'analysis_summary': {
            'dimensions_found': dict(dimension_counter),
            'units_found': dict(unit_counter),
            'context_unit': context_unit,
            'method': 'mixed_analysis'
        }
    }

def analyze_product_context_for_units(column_name, product_name=None, category=None, description=None):
    """AI-–∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–¥—É–∫—Ç–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ª–æ–≥–∏—á–Ω—ã—Ö –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è"""
    
    if not PINT_AVAILABLE:
        return None
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    column_lower = column_name.lower()
    product_lower = str(product_name).lower() if product_name else ""
    category_lower = str(category).lower() if category else ""
    description_lower = str(description).lower() if description else ""
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç
    full_context = f"{column_lower} {product_lower} {category_lower} {description_lower}"
    
    # === –ü–†–ê–í–ò–õ–ê –î–õ–Ø –†–ê–ó–ù–´–• –¢–ò–ü–û–í –ü–†–û–î–£–ö–¢–û–í ===
    
    # 1. –ù–û–£–¢–ë–£–ö–ò / –ö–û–ú–ü–¨–Æ–¢–ï–†–´
    if any(tech_word in full_context for tech_word in [
        'laptop', 'notebook', 'computer', 'pc', '–Ω–æ—É—Ç–±—É–∫', '–∫–æ–º–ø—å—é—Ç–µ—Ä'
    ]):
        # –†–∞–∑–º–µ—Ä—ã –Ω–æ—É—Ç–±—É–∫–æ–≤ –æ–±—ã—á–Ω–æ –≤ –º–º
        if any(dim_word in column_lower for dim_word in ['dimension', 'size', '—Ä–∞–∑–º–µ—Ä']):
            return 'mm'
            
        # –≠–∫—Ä–∞–Ω –Ω–æ—É—Ç–±—É–∫–∞ –≤ –¥—é–π–º–∞—Ö
        if any(screen_word in column_lower for screen_word in ['screen', 'display', '—ç–∫—Ä–∞–Ω']):
            if 'resolution' not in column_lower:  # –ù–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
                return 'inch'
                
        # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ —ç–∫—Ä–∞–Ω–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö
        if any(res_word in column_lower for res_word in ['resolution', '—Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ']):
            return 'pixel'
            
        # –í–µ—Å –Ω–æ—É—Ç–±—É–∫–∞ –≤ –∫–≥
        if any(weight_word in column_lower for weight_word in ['weight', '–≤–µ—Å']):
            return 'kg'
            
        # –ü–∞–º—è—Ç—å –≤ GB
        if any(mem_word in column_lower for mem_word in ['ram', 'memory', 'storage', '–ø–∞–º—è—Ç—å']):
            return 'GB'
    
    # 2. –¢–ï–õ–ï–§–û–ù–´ / –°–ú–ê–†–¢–§–û–ù–´
    if any(phone_word in full_context for phone_word in [
        'phone', 'smartphone', 'mobile', '—Ç–µ–ª–µ—Ñ–æ–Ω', '—Å–º–∞—Ä—Ç—Ñ–æ–Ω'
    ]):
        # –†–∞–∑–º–µ—Ä—ã —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ –æ–±—ã—á–Ω–æ –≤ –º–º
        if any(dim_word in column_lower for dim_word in ['dimension', 'size', 'width', 'height', 'length']):
            return 'mm'
            
        # –≠–∫—Ä–∞–Ω —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –≤ –¥—é–π–º–∞—Ö
        if any(screen_word in column_lower for screen_word in ['screen', 'display']):
            if 'resolution' not in column_lower:
                return 'inch'
                
        # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –≤ –ø–∏–∫—Å–µ–ª—è—Ö
        if 'resolution' in column_lower:
            return 'pixel'
            
        # –í–µ—Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –≤ –≥—Ä–∞–º–º–∞—Ö (–æ–±—ã—á–Ω–æ –ª–µ–≥–∫–∏–µ)
        if 'weight' in column_lower:
            return 'g'
    
    # 3. –¢–ï–õ–ï–í–ò–ó–û–†–´ / –ú–û–ù–ò–¢–û–†–´
    if any(tv_word in full_context for tv_word in [
        'tv', 'television', 'monitor', '—Ç–µ–ª–µ–≤–∏–∑–æ—Ä', '–º–æ–Ω–∏—Ç–æ—Ä'
    ]):
        # –≠–∫—Ä–∞–Ω –¢–í/–º–æ–Ω–∏—Ç–æ—Ä–∞ –≤ –¥—é–π–º–∞—Ö
        if any(screen_word in column_lower for screen_word in ['screen', 'display', 'size']):
            if 'resolution' not in column_lower:
                return 'inch'
                
        # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –≤ –ø–∏–∫—Å–µ–ª—è—Ö
        if 'resolution' in column_lower:
            return 'pixel'
            
        # –†–∞–∑–º–µ—Ä—ã –¢–í –≤ –º–º –∏–ª–∏ —Å–º
        if any(dim_word in column_lower for dim_word in ['dimension', 'width', 'height']):
            return 'mm'
    
    # 4. –ë–´–¢–û–í–ê–Ø –¢–ï–•–ù–ò–ö–ê
    if any(appliance_word in full_context for appliance_word in [
        'refrigerator', 'washing', 'dishwasher', 'oven', '—Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫', '—Å—Ç–∏—Ä–∞–ª—å–Ω–∞—è', '–ø–æ—Å—É–¥–æ–º–æ–π–∫–∞'
    ]):
        # –†–∞–∑–º–µ—Ä—ã –∫—Ä—É–ø–Ω–æ–π —Ç–µ—Ö–Ω–∏–∫–∏ –≤ —Å–º
        if any(dim_word in column_lower for dim_word in ['dimension', 'size', 'width', 'height']):
            return 'cm'
            
        # –í–µ—Å –∫—Ä—É–ø–Ω–æ–π —Ç–µ—Ö–Ω–∏–∫–∏ –≤ –∫–≥
        if 'weight' in column_lower:
            return 'kg'
            
        # –ú–æ—â–Ω–æ—Å—Ç—å –≤ –≤–∞—Ç—Ç–∞—Ö
        if any(power_word in column_lower for power_word in ['power', '–º–æ—â–Ω–æ—Å—Ç—å']):
            return 'W'
    
    # 5. –ê–í–¢–û–ú–û–ë–ò–õ–ò
    if any(car_word in full_context for car_word in [
        'car', 'auto', 'vehicle', '–º–∞—à–∏–Ω–∞', '–∞–≤—Ç–æ–º–æ–±–∏–ª—å'
    ]):
        # –†–∞–∑–º–µ—Ä—ã –∞–≤—Ç–æ –≤ –º–µ—Ç—Ä–∞—Ö
        if any(dim_word in column_lower for dim_word in ['length', 'width', 'height']):
            return 'm'
            
        # –ú–æ—â–Ω–æ—Å—Ç—å –¥–≤–∏–≥–∞—Ç–µ–ª—è –≤ –ª–æ—à–∞–¥–∏–Ω—ã—Ö —Å–∏–ª–∞—Ö –∏–ª–∏ –∫–í—Ç
        if any(power_word in column_lower for power_word in ['power', 'engine', '–º–æ—â–Ω–æ—Å—Ç—å']):
            return 'kW'
    
    # === –û–ë–©–ò–ï –ü–†–ê–í–ò–õ–ê –ü–û –¢–ò–ü–£ –ü–ê–†–ê–ú–ï–¢–†–ê ===
    
    # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ —ç–∫—Ä–∞–Ω–∞ –≤—Å–µ–≥–¥–∞ –≤ –ø–∏–∫—Å–µ–ª—è—Ö
    if any(res_word in column_lower for res_word in ['resolution', '—Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ']) or \
       re.search(r'\d+x\d+', str(column_name)):  # –ü–∞—Ç—Ç–µ—Ä–Ω 1920x1080
        return 'pixel'
    
    # –≠–∫—Ä–∞–Ω—ã –æ–±—ã—á–Ω–æ –≤ –¥—é–π–º–∞—Ö
    if any(screen_word in column_lower for screen_word in ['screen', 'display', 'inch', '–¥—é–π–º']):
        return 'inch'
    
    # –í–µ—Å
    if any(weight_word in column_lower for weight_word in ['weight', '–≤–µ—Å']):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É: –ª–µ–≥–∫–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –≤ –≥—Ä–∞–º–º–∞—Ö, —Ç—è–∂–µ–ª—ã–µ –≤ –∫–≥
        if any(light_device in full_context for light_device in ['phone', 'tablet', '—Ç–µ–ª–µ—Ñ–æ–Ω']):
            return 'g'
        else:
            return 'kg'
    
    # –ú–æ—â–Ω–æ—Å—Ç—å
    if any(power_word in column_lower for power_word in ['power', 'watt', '–º–æ—â–Ω–æ—Å—Ç—å']):
        return 'W'
    
    # –ü–∞–º—è—Ç—å/—Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    if any(mem_word in column_lower for mem_word in ['memory', 'storage', 'ram', 'ssd', '–ø–∞–º—è—Ç—å']):
        return 'GB'
    
    # –†–∞–∑–º–µ—Ä—ã - –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    if any(dim_word in column_lower for dim_word in ['dimension', 'size', 'width', 'height', 'length']):
        # –ú–µ–ª–∫–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –≤ –º–º
        if any(small_device in full_context for small_device in [
            'phone', 'tablet', 'laptop', '—Ç–µ–ª–µ—Ñ–æ–Ω', '–ø–ª–∞–Ω—à–µ—Ç', '–Ω–æ—É—Ç–±—É–∫'
        ]):
            return 'mm'
        # –°—Ä–µ–¥–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –≤ —Å–º
        elif any(medium_device in full_context for medium_device in [
            'tv', 'monitor', '—Ç–µ–ª–µ–≤–∏–∑–æ—Ä', '–º–æ–Ω–∏—Ç–æ—Ä'
        ]):
            return 'cm'
        # –ö—Ä—É–ø–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –≤ –º–µ—Ç—Ä–∞—Ö
        else:
            return 'm'
    
    return None

def extract_unit_from_context_optimized(column_name, product_name=None, category=None, description=None):
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è —Å AI-–∞–Ω–∞–ª–∏–∑–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–¥—É–∫—Ç–∞"""
    
    if not PINT_AVAILABLE:
        return None
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    column_lower = column_name.lower()
    
    # 1. –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ —Å–∫–æ–±–∫–∞—Ö (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
    bracket_match = re.search(r'\(([^)]+)\)', column_name)
    if bracket_match:
        potential_unit = bracket_match.group(1).strip()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ Pint
        try:
            ureg.parse_expression(potential_unit)
            return potential_unit
        except:
            pass
    
    # 2. –ò—â–µ–º –µ–¥–∏–Ω–∏—Ü—ã –≤ —Å–∞–º–æ–º –Ω–∞–∑–≤–∞–Ω–∏–∏ –∫–æ–ª–æ–Ω–∫–∏
    words = re.findall(r'\b\w+\b', column_lower)
    for word in words:
        if len(word) > 1:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–¥–Ω–æ—Å–∏–º–≤–æ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞
            try:
                ureg.parse_expression(word)
                return word
            except:
                continue
    
    # 3. –ù–û–í–´–ô: AI-–∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–¥—É–∫—Ç–∞
    ai_unit = analyze_product_context_for_units(column_name, product_name, category, description)
    if ai_unit:
        try:
            ureg.parse_expression(ai_unit)
            return ai_unit
        except:
            pass
    
    # 4. –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞ (fallback)
    context_text = f"{column_lower} {str(product_name).lower() if product_name else ''} {str(category).lower() if category else ''}"
    
    # –≠–∫—Ä–∞–Ω—ã –æ–±—ã—á–Ω–æ –≤ –¥—é–π–º–∞—Ö
    if any(screen_word in context_text for screen_word in ['screen', 'display', '—ç–∫—Ä–∞–Ω', '–¥–∏–∞–≥–æ–Ω–∞–ª—å']):
        try:
            ureg.parse_expression('inch')
            return 'inch'
        except:
            pass
    
    # –í–µ—Å –æ–±—ã—á–Ω–æ –≤ –∫–∏–ª–æ–≥—Ä–∞–º–º–∞—Ö
    if any(weight_word in context_text for weight_word in ['weight', '–≤–µ—Å']):
        try:
            ureg.parse_expression('kg')
            return 'kg'
        except:
            pass
    
    # –ú–æ—â–Ω–æ—Å—Ç—å –æ–±—ã—á–Ω–æ –≤ –≤–∞—Ç—Ç–∞—Ö
    if any(power_word in context_text for power_word in ['power', '–º–æ—â–Ω–æ—Å—Ç—å']):
        try:
            ureg.parse_expression('W')
            return 'W'
        except:
            pass
    
    # –ü–∞–º—è—Ç—å –æ–±—ã—á–Ω–æ –≤ –≥–∏–≥–∞–±–∞–π—Ç–∞—Ö
    if any(mem_word in context_text for mem_word in ['memory', 'storage', '–ø–∞–º—è—Ç—å']):
        try:
            ureg.parse_expression('GB')
            return 'GB'
        except:
            pass
    
    return None

# –ì—Ä—É–ø–ø–æ–≤–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
def analyze_units_by_category(df, column_name, category_column='group_name', sample_size=3):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Å AI-–∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø—Ä–æ–¥—É–∫—Ç–∞"""
    
    if not PINT_AVAILABLE:
        return {}
    
    category_units = {}
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    if category_column not in df.columns:
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—É—é –∫–æ–ª–æ–Ω–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        for alt_col in ['Category', 'category', 'group_name']:
            if alt_col in df.columns:
                category_column = alt_col
                break
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–π AI-–∞–Ω–∞–ª–∏–∑
            sample_row = df.iloc[0] if len(df) > 0 else {}
            product_name = sample_row.get('product_name', sample_row.get('name', ''))
            description = sample_row.get('description', '')
            ai_unit = analyze_product_context_for_units(column_name, product_name, None, description)
            return {'default': ai_unit or extract_unit_from_context_optimized(column_name, product_name, None, description)}
    
    for category, group_df in df.groupby(category_column):
        if pd.isna(category):
            continue
            
        # –ë–µ—Ä–µ–º –æ–±—Ä–∞–∑—Ü—ã —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è AI-–∞–Ω–∞–ª–∏–∑–∞
        sample_rows = group_df.head(sample_size)
        
        if len(sample_rows) == 0:
            continue
        
        # === –ù–û–í–´–ô: AI-–ê–ù–ê–õ–ò–ó 2-3 –¢–û–í–ê–†–û–í –ò–ó –ö–ê–¢–ï–ì–û–†–ò–ò ===
        ai_suggestions = []
        
        for idx, row in sample_rows.iterrows():
            product_name = row.get('product_name', row.get('name', ''))
            description = row.get('description', '')
            
            # AI-–∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
            ai_unit = analyze_product_context_for_units(
                column_name, product_name, str(category), description
            )
            
            if ai_unit:
                ai_suggestions.append(ai_unit)
        
        # –í—ã–±–∏—Ä–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—É—é AI-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        category_unit = None
        if ai_suggestions:
            unit_counter = Counter(ai_suggestions)
            most_common_ai_unit = unit_counter.most_common(1)
            if most_common_ai_unit:
                category_unit = most_common_ai_unit[0][0]
        
        # === FALLBACK: –ê–ù–ê–õ–ò–ó –ó–ù–ê–ß–ï–ù–ò–ô –í –ö–û–õ–û–ù–ö–ï ===
        if not category_unit:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∞–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ–ª–æ–Ω–∫–µ
            sample_values = group_df[column_name].dropna().head(sample_size)
            
            for value in sample_values:
                value_str = str(value).strip()
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω —á–∏—Å–ª–æ + –µ–¥–∏–Ω–∏—Ü–∞
                unit_match = re.search(r'\d+\.?\d*\s*([a-zA-Z–∞-—è—ë¬∞"\'\s]+)', value_str)
                if unit_match:
                    potential_unit = unit_match.group(1).strip()
                    if potential_unit and len(potential_unit) < 10:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ Pint
                        try:
                            ureg.parse_expression(potential_unit)
                            category_unit = potential_unit
                            break
                        except:
                            continue
        
        # === –ü–û–°–õ–ï–î–ù–ò–ô FALLBACK: –ö–û–ù–¢–ï–ö–°–¢–ù–´–ô –ê–ù–ê–õ–ò–ó ===
        if not category_unit:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–æ–≤–∞—Ä–µ
            sample_row = sample_rows.iloc[0]
            product_name = sample_row.get('product_name', sample_row.get('name', ''))
            description = sample_row.get('description', '')
            category_unit = extract_unit_from_context_optimized(column_name, product_name, str(category), description)
        
        if category_unit:
            category_units[str(category)] = category_unit
    
    return category_units

# –ö—ç—à –¥–ª—è –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –µ–¥–∏–Ω–∏—Ü
@st.cache_data
def get_category_units_cache(df_hash, column_name, category_column):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä—É–ø–ø–æ–≤–æ–π –∞–Ω–∞–ª–∏–∑ –µ–¥–∏–Ω–∏—Ü –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π DataFrame –∏–∑ —Ö—ç—à–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
    # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–Ω –≤–µ—Å—å DataFrame
    return {}

def standardize_value_intelligent_optimized(value, target_format=None, column_name=None, product_name=None, category=None, category_units=None, description=None):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è —Å AI-–∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø—Ä–æ–¥—É–∫—Ç–∞"""
    if pd.isna(value):
        return value
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    if not hasattr(standardize_value_intelligent_optimized, '_extractor'):
        standardize_value_intelligent_optimized._extractor = IntelligentUnitExtractor()
    
    extractor = standardize_value_intelligent_optimized._extractor
    extractions = extractor.extract_all_methods(value)
    
    # –ï—Å–ª–∏ AI –Ω–µ –Ω–∞—à–µ–ª –µ–¥–∏–Ω–∏—Ü—ã –≤ –∑–Ω–∞—á–µ–Ω–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    if not extractions and column_name:
        unit_from_context = None
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä—É–ø–ø–æ–≤–æ–π –∫—ç—à –µ–¥–∏–Ω–∏—Ü –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if category_units and category in category_units:
            unit_from_context = category_units[category]
        elif category_units and 'default' in category_units:
            unit_from_context = category_units['default']
        else:
            # AI-–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–æ–¥—É–∫—Ç–µ
            unit_from_context = analyze_product_context_for_units(column_name, product_name, category, description)
            if not unit_from_context:
                unit_from_context = extract_unit_from_context_optimized(column_name, product_name, category, description)
        
        if unit_from_context:
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ –∏–∑ –∑–Ω–∞—á–µ–Ω–∏—è
            value_str = str(value).strip()
            number_match = re.search(r'(\d+\.?\d*)', value_str)
            if number_match:
                number = float(number_match.group(1))
                
                # –°–æ–∑–¥–∞–µ–º "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–µ" –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ AI-–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                artificial_extraction = {
                    'value': number,
                    'unit': unit_from_context,
                    'unit_symbol': unit_from_context,
                    'dimension': 'ai_product_context',
                    'confidence': 0.95,  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è AI-–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                    'method': 'ai_product_context_analysis'
                }
                extractions = [artificial_extraction]
    
    if not extractions:
        return value
    
    # –ë–µ—Ä–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –Ω–∞–∏–≤—ã—Å—à–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
    best_extraction = max(extractions, key=lambda x: x.get('confidence', 0))
    
    if best_extraction.get('confidence', 0) < confidence_threshold:
        return value
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    number = best_extraction.get('value', '')
    unit = best_extraction.get('unit', '')
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—è Pint, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫—É—é –µ–¥–∏–Ω–∏—Ü—É
    pint_val = best_extraction.get('pint_validation', {})
    if pint_val.get('is_valid') and pint_val.get('canonical_unit'):
        unit = pint_val['canonical_unit']
    
    if target_format == 'number_unit':
        return f"{number} {unit}"
    elif target_format == 'unit_number':
        return f"{unit} {number}"
    else:
        return f"{number} {unit}"

def standardize_value_simple_optimized(value, target_format='number_unit', column_name=None, product_name=None, category=None, category_units=None, description=None):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ—Å—Ç–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è —Å AI-–∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø—Ä–æ–¥—É–∫—Ç–∞"""
    if pd.isna(value):
        return value
    
    value_str = str(value).strip()
    
    # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω: —á–∏—Å–ª–æ + –µ–¥–∏–Ω–∏—Ü–∞
    pattern = r'(\d+\.?\d*)\s*([a-zA-Z–∞-—è—ë¬∞"\'\s]*)'
    match = re.search(pattern, value_str)
    
    if match:
        number = match.group(1)
        unit = match.group(2).strip()
        
        # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ –ø—É—Å—Ç–∞—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º AI-–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        if not unit and column_name:
            unit_from_context = None
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä—É–ø–ø–æ–≤–æ–π –∫—ç—à –µ–¥–∏–Ω–∏—Ü –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            if category_units and category in category_units:
                unit_from_context = category_units[category]
            elif category_units and 'default' in category_units:
                unit_from_context = category_units['default']
            else:
                # AI-–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–æ–¥—É–∫—Ç–µ
                unit_from_context = analyze_product_context_for_units(column_name, product_name, category, description)
                if not unit_from_context:
                    unit_from_context = extract_unit_from_context_optimized(column_name, product_name, category, description)
            
            if unit_from_context:
                unit = unit_from_context
        
        # –ï—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü–∞ –≤—Å–µ –µ—â–µ –ø—É—Å—Ç–∞—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not unit:
            return value
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
        if target_format == 'number_unit':
            return f"{number} {unit}"
        elif target_format == 'unit_number':
            return f"{unit} {number}"
        else:
            return f"{number} {unit}"
    
    return value

# –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞–∫–µ—Ç–Ω–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
def batch_standardize_column_optimized(df, column_name, standardization_format, use_ai=False, category_column='group_name'):
    """–ü–∞–∫–µ—Ç–Ω–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∫–æ–ª–æ–Ω–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º AI-–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    
    # –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –µ–¥–∏–Ω–∏—Ü—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å AI-–∞–Ω–∞–ª–∏–∑–æ–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤
    category_units = analyze_units_by_category(df, column_name, category_column, sample_size=3)
    
    results = []
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≥—Ä—É–ø–ø–∞–º –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    if category_column in df.columns:
        for category, group_df in df.groupby(category_column):
            if pd.isna(category):
                category = 'default'
            
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            for idx, row in group_df.iterrows():
                value = row[column_name]
                product_name = row.get('product_name', row.get('name', ''))
                description = row.get('description', '')
                
                if use_ai:
                    standardized = standardize_value_intelligent_optimized(
                        value, standardization_format, column_name, product_name, str(category), category_units, description
                    )
                else:
                    standardized = standardize_value_simple_optimized(
                        value, standardization_format, column_name, product_name, str(category), category_units, description
                    )
                results.append((idx, standardized))
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
        for idx, row in df.iterrows():
            value = row[column_name]
            product_name = row.get('product_name', row.get('name', ''))
            description = row.get('description', '')
            
            if use_ai:
                standardized = standardize_value_intelligent_optimized(
                    value, standardization_format, column_name, product_name, None, category_units, description
                )
            else:
                standardized = standardize_value_simple_optimized(
                    value, standardization_format, column_name, product_name, None, category_units, description
                )
            results.append((idx, standardized))
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –∏–Ω–¥–µ–∫—Å–æ–≤
    results_dict = dict(results)
    return [results_dict.get(idx, df.loc[idx, column_name]) for idx in df.index]

def analyze_column_statistics_intelligent(df, column):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–æ–ª–æ–Ω–∫–∏"""
    values = df[column].dropna()
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    extraction_stats = {
        'quantulum_extractions': 0,
        'transformer_extractions': 0,
        'pint_validations': 0,
        'total_extractions': 0
    }
    
    numeric_values = []
    units_found = Counter()
    dimensions_found = Counter()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    if not hasattr(analyze_column_statistics_intelligent, '_extractor'):
        analyze_column_statistics_intelligent._extractor = IntelligentUnitExtractor()
    
    extractor = analyze_column_statistics_intelligent._extractor
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—Ä–∞–∑–µ—Ü –∑–Ω–∞—á–µ–Ω–∏–π
    sample_size = min(max_samples, len(values))
    for value in values.head(sample_size):
        extractions = extractor.extract_all_methods(value)
        
        extraction_stats['total_extractions'] += len(extractions)
        
        for extraction in extractions:
            method = extraction.get('method', 'unknown')
            if method == 'quantulum3':
                extraction_stats['quantulum_extractions'] += 1
            elif method == 'transformers':
                extraction_stats['transformer_extractions'] += 1
            
            if extraction.get('pint_validation', {}).get('is_valid'):
                extraction_stats['pint_validations'] += 1
            
            if extraction.get('confidence', 0) >= confidence_threshold:
                numeric_values.append(extraction.get('value', 0))
                units_found[extraction.get('unit', '')] += 1
                
                dimension = extraction.get('dimension', '')
                if dimension:
                    dimensions_found[dimension] += 1
    
    stats = {
        'total_values': len(values),
        'analyzed_values': sample_size,
        'numeric_count': len(numeric_values),
        'extraction_stats': extraction_stats,
        'units_found': dict(units_found.most_common(10)),
        'dimensions_found': dict(dimensions_found.most_common(5)),
        'numeric_stats': {}
    }
    
    if numeric_values:
        stats['numeric_stats'] = {
            'min': min(numeric_values),
            'max': max(numeric_values),
            'mean': sum(numeric_values) / len(numeric_values),
            'count': len(numeric_values)
        }
    
    return stats

# --- –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---

if not df_param.empty:
    st.dataframe(df_param.head(20))
    all_columns = list(df_param.columns)

    # –ò—Å–∫–ª—é—á–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
    system_columns = [
        col for col in all_columns
        if any(keyword in col.lower() for keyword in [
            'name', 'id', 'source_file', 'category', 'group_name',  # —Å–∏—Å—Ç–µ–º–Ω—ã–µ
            'sku', 'width',  # –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            'price', 'cost', '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å'  # —Ü–∏—Ñ—Ä–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        ])
    ]

    st.markdown("#### –ò—Å–∫–ª—é—á–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞")
    excluded_cols = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å:",
        options=all_columns,
        default=system_columns,
        help="–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–∫–ª—é—á–µ–Ω—ã: —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏, SKU, Width, —Ü–µ–Ω—ã"
    )

    analysis_columns = [c for c in all_columns if c not in excluded_cols]
    
    if analysis_columns:
        st.success(f"‚úÖ –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ—Å—Ç—É–ø–Ω–æ {len(analysis_columns)} –∫–æ–ª–æ–Ω–æ–∫: {', '.join(analysis_columns[:5])}{'...' if len(analysis_columns) > 5 else ''}")
    else:
        st.warning("‚ùå –ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –í—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω—ã.")
    
    # --- –≠—Ç–∞–ø 1: –ë—ã—Å—Ç—Ä–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ ---
    with st.expander("#### 1. üî¢ –ë—ã—Å—Ç—Ä–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫", expanded=True):
        st.markdown("**–ü–æ–∏—Å–∫ –∫–æ–ª–æ–Ω–æ–∫ —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö —Ü–∏—Ñ—Ä—ã –∏–ª–∏ —Ü–∏—Ñ—Ä—ã + –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è**")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã –ò–ò –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —ç—Ç–∞–ø–æ–≤
        active_methods = []
        if use_quantulum:
            active_methods.append("üîç Quantulum3")
        if use_transformers:
            active_methods.append("ü§ñ Transformer-NER")
        if use_pint:
            active_methods.append("üìê Pint")
        
        if active_methods:
            st.info(f"–ú–µ—Ç–æ–¥—ã –ò–ò –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —ç—Ç–∞–ø–æ–≤: {', '.join(active_methods)}")
            st.success("üß† **–ù–û–í–û–ï**: AI –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç 2-3 —Ç–æ–≤–∞—Ä–∞ –∏–∑ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è")
            if use_transformers and TRANSFORMERS_AVAILABLE:
                st.info("‚ÑπÔ∏è Transformer –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è)")
        
        if st.button("üîç –ù–∞–π—Ç–∏ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏", key="find_numeric_simple"):
            if not analysis_columns:
                st.warning("–ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è.")
            else:
                with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫–∏..."):
                    # –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑
                    numeric_analysis = quick_find_numeric_columns(df_param, analysis_columns)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    st.session_state['numeric_analysis_simple'] = numeric_analysis
                    
                    if numeric_analysis:
                        st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(numeric_analysis)} –∫–æ–ª–æ–Ω–æ–∫ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏!")
                    else:
                        st.warning("‚ùå –ö–æ–ª–æ–Ω–∫–∏ —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ—Å—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        if 'numeric_analysis_simple' in st.session_state and st.session_state['numeric_analysis_simple']:
            st.markdown("**üìä –ù–∞–π–¥–µ–Ω–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏**")
            
            analysis_data = []
            for column, stats in st.session_state['numeric_analysis_simple'].items():
                row = {
                    '–ö–æ–ª–æ–Ω–∫–∞': column,
                    '–í—Å–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–π': stats['total_values'],
                    '–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ': stats['analyzed_values'],
                    '–° —Ü–∏—Ñ—Ä–∞–º–∏': stats['numeric_count'],
                    '% —á–∏—Å–ª–æ–≤—ã—Ö': f"{stats['numeric_percentage']:.1f}%",
                    '–ù–∞–π–¥–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã': ', '.join(list(stats['units_found'].keys())[:3]),
                    '–ü—Ä–∏–º–µ—Ä—ã —á–∏—Å–µ–ª': ', '.join([str(v) for v in stats['numeric_values'][:3]]),
                    '–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ': f"{stats['avg_value']:.2f}" if stats['avg_value'] > 0 else "-"
                }
                analysis_data.append(row)
            
            analysis_df = pd.DataFrame(analysis_data)
            st.dataframe(analysis_df, use_container_width=True)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏
            selected_col = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ø—Ä–∏–º–µ—Ä–æ–≤:",
                options=list(st.session_state['numeric_analysis_simple'].keys())
            )
            
            if selected_col:
                st.markdown(f"**–ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ '{selected_col}':**")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–¥–µ –Ω–∞–π—Ç–∏ –∫–æ–ª–æ–Ω–∫—É - –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
                if selected_col in df_param.columns:
                    # –ö–æ–ª–æ–Ω–∫–∞ –µ—â–µ –Ω–µ –±—ã–ª–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
                    sample_values = df_param[selected_col].dropna().head(10).tolist()
                elif 'df_standardization' in st.session_state:
                    # –ò—â–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –∫–æ–ª–æ–Ω–∫–∏
                    standardized_col = None
                    for col in st.session_state['df_standardization'].columns:
                        if selected_col in col and "(" in col and ")" in col:
                            standardized_col = col
                            break
                    
                    if standardized_col:
                        sample_values = st.session_state['df_standardization'][standardized_col].dropna().head(10).tolist()
                        st.info(f"–ü–æ–∫–∞–∑–∞–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏: {standardized_col}")
                    else:
                        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                        if selected_col in st.session_state['df_standardization'].columns:
                            sample_values = st.session_state['df_standardization'][selected_col].dropna().head(10).tolist()
                        else:
                            st.warning("–ö–æ–ª–æ–Ω–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∏ –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö, –Ω–∏ –≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                            sample_values = []
                else:
                    st.warning("–î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    sample_values = []
                
                if sample_values:
                    for i, value in enumerate(sample_values, 1):
                        # –ü–æ–¥—Å–≤–µ—á–∏–≤–∞–µ–º —Ü–∏—Ñ—Ä—ã –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö
                        value_str = str(value)
                        highlighted = re.sub(r'(\d+\.?\d*)', r'**\1**', value_str)
                        st.write(f"{i}. {highlighted}")

    # --- –≠—Ç–∞–ø 2: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è ---
    with st.expander("#### 2. üß† –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è", expanded=False):
        st.markdown("**AI-–∞–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –∏–∑–º–µ—Ä–µ–Ω–∏–π –∏ –µ–¥–∏–Ω–∏—Ü –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫**")

        if 'numeric_analysis_simple' in st.session_state and st.session_state['numeric_analysis_simple']:
            if st.button("üîç –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è (AI)", key="detect_units_ai"):
                measurement_analysis = {}
                progress_bar = st.progress(0)
                columns_to_analyze = list(st.session_state['numeric_analysis_simple'].keys())

                with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ–º AI-–∞–Ω–∞–ª–∏–∑ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è..."):
                    for i, column in enumerate(columns_to_analyze):
                        progress_bar.progress((i + 1) / len(columns_to_analyze))
                        # –ë–µ—Ä–µ–º –æ–±—Ä–∞–∑–µ—Ü –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                        sample_values = df_param[column].dropna().head(max_samples).tolist()
                        analysis_result = detect_measurement_type_intelligent(column, sample_values, use_quantulum=True, use_transformers=True, use_pint=True)
                        measurement_analysis[column] = {
                            'type': analysis_result['primary_dimension'],
                            'confidence': analysis_result['confidence'],
                            'common_units': analysis_result['common_units'],
                            'analysis_summary': analysis_result['analysis_summary'],
                            'sample_values': sample_values[:10]
                        }
                progress_bar.empty()
                st.session_state['measurement_analysis_ai'] = measurement_analysis
                st.success("‚úÖ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω!")
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–¥–∏–Ω–∏—Ü
            if 'measurement_analysis_ai' in st.session_state:
                st.markdown("**üß† –†–µ–∑—É–ª—å—Ç–∞—Ç—ã AI-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è**")
                
                measurement_data = []
                for column, analysis in st.session_state['measurement_analysis_ai'].items():
                    row = {
                        '–ö–æ–ª–æ–Ω–∫–∞': column,
                        '–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å': analysis['type'],
                        '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': f"{analysis['confidence']:.2f}",
                        '–ù–∞–π–¥–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã': ', '.join(analysis['common_units'][:5]),
                        '–ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π': ', '.join([str(v) for v in analysis['sample_values'][:3]]),
                        '–ú–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞': analysis['analysis_summary'].get('method', 'unknown'),
                        '–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞': analysis['analysis_summary'].get('context_unit', '–ù–µ—Ç')
                    }
                    measurement_data.append(row)
                
                measurement_df = pd.DataFrame(measurement_data)
                st.dataframe(measurement_df, use_container_width=True)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
                successful_analyses = sum(1 for analysis in st.session_state['measurement_analysis_ai'].values() if analysis['confidence'] > 0)
                total_analyses = len(st.session_state['measurement_analysis_ai'])
                success_rate = (successful_analyses / total_analyses * 100) if total_analyses > 0 else 0
                
                st.info(f"üìà **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞**: {successful_analyses} –∏–∑ {total_analyses} –∫–æ–ª–æ–Ω–æ–∫ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã ({success_rate:.1f}% —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏)")
                
                # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                selected_column = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:",
                    options=list(st.session_state['measurement_analysis_ai'].keys())
                )
                
                if selected_column:
                    analysis = st.session_state['measurement_analysis_ai'][selected_column]
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.markdown("**–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏:**")
                        dimensions = analysis['analysis_summary']['dimensions_found']
                        for dim, count in dimensions.items():
                            st.write(f"‚Ä¢ {dim}: {count}")
                    
                    with col2:
                        st.markdown("**–ù–∞–π–¥–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã:**")
                        units = analysis['analysis_summary']['units_found']
                        for unit, count in units.items():
                            st.write(f"‚Ä¢ {unit}: {count}")
                    
                    with col3:
                        st.markdown("**–û–±—Ä–∞–∑—Ü—ã –∑–Ω–∞—á–µ–Ω–∏–π:**")
                        for value in analysis['sample_values'][:5]:
                            st.write(f"‚Ä¢ {value}")
        else:
            st.info("–°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–∏—Ç–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ä–∞–∑–¥–µ–ª–µ –≤—ã—à–µ.")

    # --- –≠—Ç–∞–ø 3: –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π ---
    with st.expander("#### 3. ‚öôÔ∏è –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π", expanded=False):
        st.markdown("**–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ (–∏—Å–∫–ª—é—á–∏—Ç–µ –Ω–µ–Ω—É–∂–Ω—ã–µ)**")
        
        # –í—ã–±–æ—Ä —Ç–∏–ø–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
        use_ai_standardization = st.checkbox(
            "üß† –£–º–Ω–∞—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è (AI)", 
            value=False,
            help="AI –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫ —á–∏—Å–ª–∞–º"
        )
        
        if use_ai_standardization:
            st.info("‚ÑπÔ∏è AI-—Ä–µ–∂–∏–º: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü + –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
        else:
            st.info("‚ö° –ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º: –ø—Ä–æ—Å—Ç–æ–µ regex —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ + AI-–∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
        
        # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
        if 'numeric_analysis_simple' in st.session_state and st.session_state['numeric_analysis_simple']:
            available_columns = list(st.session_state['numeric_analysis_simple'].keys())
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            columns_with_low_confidence = []
            if 'measurement_analysis_ai' in st.session_state:
                for column, analysis in st.session_state['measurement_analysis_ai'].items():
                    if analysis['confidence'] < 0.3:  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                        columns_with_low_confidence.append(column)
            
            st.markdown("**–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ò–°–ö–õ–Æ–ß–ï–ù–ò–Ø –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏:**")
            excluded_columns = st.multiselect(
                "–ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è:",
                options=available_columns,
                default=columns_with_low_confidence,
                help="–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–∫–ª—é—á–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–¥–∏–Ω–∏—Ü (< 30%)"
            )
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ (–≤—Å–µ –∫—Ä–æ–º–µ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö)
            selected_columns = [col for col in available_columns if col not in excluded_columns]
            
            if selected_columns:
                st.success(f"‚úÖ –î–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ –≤—ã–±—Ä–∞–Ω–æ {len(selected_columns)} –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ {len(available_columns)}")
                if excluded_columns:
                    st.info(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–æ {len(excluded_columns)} –∫–æ–ª–æ–Ω–æ–∫: {', '.join(excluded_columns[:3])}{'...' if len(excluded_columns) > 3 else ''}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
                with st.expander("üìã –ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏", expanded=False):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown("**–ë—É–¥—É—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω—ã:**")
                        for col in selected_columns:
                            confidence = ""
                            if 'measurement_analysis_ai' in st.session_state and col in st.session_state['measurement_analysis_ai']:
                                conf_val = st.session_state['measurement_analysis_ai'][col]['confidence']
                                confidence = f" (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf_val:.2f})"
                            st.write(f"‚úÖ {col}{confidence}")
                    
                    with col2:
                        if excluded_columns:
                            st.markdown("**–ò—Å–∫–ª—é—á–µ–Ω—ã –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏:**")
                            for col in excluded_columns:
                                confidence = ""
                                if 'measurement_analysis_ai' in st.session_state and col in st.session_state['measurement_analysis_ai']:
                                    conf_val = st.session_state['measurement_analysis_ai'][col]['confidence']
                                    confidence = f" (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {conf_val:.2f})"
                                st.write(f"‚ùå {col}{confidence}")
            else:
                st.warning("‚ö†Ô∏è –í—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω—ã –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏")
            
            if selected_columns:
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                standardization_format = 'number_unit'  # –ß–∏—Å–ª–æ –ï–¥–∏–Ω–∏—Ü–∞ (100 kg)
                
                # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
                if st.button("üëÅÔ∏è –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏", key="preview_standardization"):
                    st.markdown("**üîç –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫:**")
                    
                    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞
                    preview_data = []
                    
                    # –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –µ–¥–∏–Ω–∏—Ü—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –æ–¥–∏–Ω —Ä–∞–∑
                    category_units_cache = {}
                    
                    for column in selected_columns:
                        # –ü–æ–ª—É—á–∞–µ–º –µ–¥–∏–Ω–∏—Ü—ã –¥–ª—è —ç—Ç–æ–π –∫–æ–ª–æ–Ω–∫–∏ (–∫—ç—à–∏—Ä—É–µ–º –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)
                        if column not in category_units_cache:
                            category_units_cache[column] = analyze_units_by_category(df_param, column, 'group_name', 3)
                        category_units = category_units_cache[column]
                        
                        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –Ω–µ–ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏
                        sample_value = None
                        for value in df_param[column].dropna().head(10):
                            if pd.notna(value) and str(value).strip():
                                sample_value = value
                                break
                        
                        if sample_value is not None:
                            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–¥—É–∫—Ç–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                            value_row = df_param[df_param[column] == sample_value]
                            if not value_row.empty:
                                product_name = value_row.get('product_name', pd.Series([None])).iloc[0]
                                category = value_row.get('group_name', pd.Series([None])).iloc[0]
                                description = value_row.get('description', pd.Series([None])).iloc[0]
                            else:
                                product_name = None
                                category = None
                                description = None
                            
                            # –í—ã–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é
                            if use_ai_standardization:
                                standardized = standardize_value_intelligent_optimized(
                                    sample_value, standardization_format, column, product_name, category, category_units, description
                                )
                            else:
                                standardized = standardize_value_simple_optimized(
                                    sample_value, standardization_format, column, product_name, category, category_units, description
                                )
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ç–∞–±–ª–∏—Ü—É –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞
                            preview_data.append({
                                '–ö–æ–ª–æ–Ω–∫–∞': column,
                                '–î–æ': str(sample_value),
                                '–ü–æ—Å–ª–µ': str(standardized),
                                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': "‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –µ–¥–∏–Ω–∏—Ü–∞" if str(sample_value) != str(standardized) else "‚ÑπÔ∏è –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π"
                            })
                        else:
                            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–π
                            preview_data.append({
                                '–ö–æ–ª–æ–Ω–∫–∞': column,
                                '–î–æ': "‚Äî",
                                '–ü–æ—Å–ª–µ': "‚Äî", 
                                '–ò–∑–º–µ–Ω–µ–Ω–∏–µ': "‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
                            })
                    
                    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
                    if preview_data:
                        preview_df = pd.DataFrame(preview_data)
                        st.dataframe(preview_df, use_container_width=True, hide_index=True)
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                        changed_count = len([row for row in preview_data if "‚úÖ" in row['–ò–∑–º–µ–Ω–µ–Ω–∏–µ']])
                        unchanged_count = len([row for row in preview_data if "‚ÑπÔ∏è" in row['–ò–∑–º–µ–Ω–µ–Ω–∏–µ']])
                        error_count = len([row for row in preview_data if "‚ùå" in row['–ò–∑–º–µ–Ω–µ–Ω–∏–µ']])
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("‚úÖ –ë—É–¥—É—Ç –∏–∑–º–µ–Ω–µ–Ω—ã", changed_count)
                        with col2:
                            st.metric("‚ÑπÔ∏è –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π", unchanged_count)
                        with col3:
                            st.metric("‚ùå –û—à–∏–±–∫–∏", error_count)
                    else:
                        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞")
                
                # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
                button_text = "üß† –ü—Ä–∏–º–µ–Ω–∏—Ç—å AI-—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é" if use_ai_standardization else "‚ö° –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä–æ—Å—Ç—É—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é"
                
                if st.button(button_text, key="apply_standardization"):
                    with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é..."):
                        progress_bar = st.progress(0)
                        
                        for i, column in enumerate(selected_columns):
                            progress_bar.progress((i + 1) / len(selected_columns))
                            
                            # –í—ã–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é
                            standardized_values = batch_standardize_column_optimized(
                                df_param, column, standardization_format, use_ai_standardization, 'group_name'
                            )
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
                            unit_for_header = None
                            if 'measurement_analysis_ai' in st.session_state and column in st.session_state['measurement_analysis_ai']:
                                common_units = st.session_state['measurement_analysis_ai'][column]['common_units']
                                if common_units:
                                    unit_for_header = common_units[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é (–Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—É—é) –µ–¥–∏–Ω–∏—Ü—É
                            
                            # –ï—Å–ª–∏ –Ω–µ—Ç –µ–¥–∏–Ω–∏—Ü—ã –∏–∑ AI-–∞–Ω–∞–ª–∏–∑–∞, –ø—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                            if not unit_for_header:
                                category_units = analyze_units_by_category(df_param, column, 'group_name', 3)
                                if category_units:
                                    unit_for_header = list(category_units.values())[0] if category_units else None
                            
                            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å –µ–¥–∏–Ω–∏—Ü–µ–π –≤ —Å–∫–æ–±–∫–∞—Ö (–µ—Å–ª–∏ –µ—ë –Ω–µ—Ç)
                            if unit_for_header and f"({unit_for_header})" not in column:
                                new_column_name = f"{column} ({unit_for_header})"
                            else:
                                new_column_name = column
                            
                            # –ó–ê–ú–ï–ù–Ø–ï–ú —Å—Ç–∞—Ä—É—é –∫–æ–ª–æ–Ω–∫—É –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é (–Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é)
                            st.session_state['df_standardization'][new_column_name] = standardized_values
                            
                            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –∫–æ–ª–æ–Ω–∫—É –µ—Å–ª–∏ –∏–º—è –∏–∑–º–µ–Ω–∏–ª–æ—Å—å
                            if new_column_name != column and column in st.session_state['df_standardization'].columns:
                                st.session_state['df_standardization'].drop(columns=[column], inplace=True)
                        
                        progress_bar.empty()
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                        new_cols_count = len(selected_columns)
                        method_name = "AI-—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏" if use_ai_standardization else "–ø—Ä–æ—Å—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏"
                        
                        st.success(f"‚úÖ {method_name} –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                        st.info(f"üìä –ó–∞–º–µ–Ω–µ–Ω–æ {new_cols_count} –∫–æ–ª–æ–Ω–æ–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –±—ã–ª–∏ –∑–∞–º–µ–Ω–µ–Ω—ã
                        replaced_columns = []
                        for column in selected_columns:
                            # –ò—â–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏
                            standardized_version = None
                            for col in st.session_state['df_standardization'].columns:
                                if column in col and "(" in col and ")" in col:
                                    standardized_version = col
                                    break
                            if standardized_version:
                                replaced_columns.append(f"{column} ‚Üí {standardized_version}")
                        
                        if replaced_columns:
                            with st.expander("üìã –ó–∞–º–µ–Ω–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏", expanded=True):
                                st.markdown("**–ö–æ–ª–æ–Ω–∫–∏ –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏:**")
                                for replacement in replaced_columns:
                                    st.write(f"‚Ä¢ {replacement}")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        st.markdown("**–ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:**")
                        
                        # –ù–∞—Ö–æ–¥–∏–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏
                        standardized_columns_with_units = [
                            col for col in st.session_state['df_standardization'].columns 
                            if any(orig_col in col for orig_col in selected_columns) and "(" in col and ")" in col
                        ]
                        
                        for column in standardized_columns_with_units[:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–ª—è –ø–µ—Ä–≤—ã—Ö 2 –∫–æ–ª–æ–Ω–æ–∫
                            # –ù–∞—Ö–æ–¥–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏
                            original_col = None
                            for orig in selected_columns:
                                if orig in column:
                                    original_col = orig
                                    break
                            
                            if original_col and original_col in df_param.columns:
                                sample_comparison = []
                                original_values = df_param[original_col].dropna().head(3).tolist()
                                standardized_values = st.session_state['df_standardization'][column].dropna().head(3).tolist()
                                
                                for orig, stand in zip(original_values, standardized_values):
                                    sample_comparison.append({
                                        '–û—Ä–∏–≥–∏–Ω–∞–ª': orig,
                                        '–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–æ': stand,
                                        '–ö–æ–ª–æ–Ω–∫–∞': column
                                    })
                                
                                if sample_comparison:
                                    comparison_df = pd.DataFrame(sample_comparison)
                                    st.dataframe(comparison_df, use_container_width=True)
            else:
                st.warning("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏")
        else:
            st.info("–°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–∏—Ç–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —ç—Ç–∞–ø–µ 1.")


    # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
    with st.expander("#### 5. üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", expanded=False):
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        if 'df_standardization' in st.session_state:
            current_df = st.session_state['df_standardization']
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (—Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –≤ —Å–∫–æ–±–∫–∞—Ö)
            standardized_columns = [col for col in current_df.columns if "(" in col and ")" in col]
            total_columns = len(current_df.columns)
            
            st.info(f"üìä –ì–æ—Ç–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞: {len(current_df)} —Å—Ç—Ä–æ–∫, {total_columns} –∫–æ–ª–æ–Ω–æ–∫")
            
            if standardized_columns:
                st.success(f"‚úÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(standardized_columns)} –∏–∑ {total_columns}")
                st.info(f"üìù –ü—Ä–∏–º–µ—Ä—ã: {', '.join(standardized_columns[:3])}{'...' if len(standardized_columns) > 3 else ''}")
        else:
            st.warning("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ standard.csv", key="save_main_ai"):
                try:
                    output_path = os.path.join(os.path.dirname(__file__), '..', 'standard.csv')
                    current_df = st.session_state.get('df_standardization', df_param)
                    current_df.to_csv(output_path, index=False, encoding='utf-8-sig')
                    st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
                    st.success(f"üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(current_df)} —Å—Ç—Ä–æ–∫, {len(current_df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
        
        with col2:
            if st.button("üì• –°–∫–∞—á–∞—Ç—å –∫–∞–∫ CSV", key="download_csv_ai"):
                current_df = st.session_state.get('df_standardization', df_param)
                csv_data = current_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª",
                    data=csv_data,
                    file_name="standard.csv",
                    mime="text/csv",
                    key="download_ai_standardized"
                )
        
        with col3:
            if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", key="reload_data_ai"):
                # –û—á–∏—â–∞–µ–º –∫—ç—à –∏ session state
                for key in ['df_standardization', 'numeric_analysis_simple', 'measurement_analysis_ai', 'standardization_results']:
                    if key in st.session_state:
                        del st.session_state[key]
                
                # –û—á–∏—â–∞–µ–º –∫—ç—à —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤
                for func in [extract_numeric_values_intelligent, detect_measurement_type_intelligent, 
                           standardize_value_intelligent_optimized, analyze_column_statistics_intelligent]:
                    if hasattr(func, '_extractor'):
                        delattr(func, '_extractor')
                
                # –û—á–∏—â–∞–µ–º –∫—ç—à Streamlit
                st.cache_resource.clear()
                
                st.success("–î–∞–Ω–Ω—ã–µ –∏ –∫—ç—à –æ–±–Ω–æ–≤–ª–µ–Ω—ã! –°—Ç—Ä–∞–Ω–∏—Ü–∞ –±—É–¥–µ—Ç –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
                st.rerun()


else:
    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –≥–ª–∞–≤–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏.")
