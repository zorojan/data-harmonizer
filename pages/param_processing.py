import streamlit as st
import pandas as pd
from rapidfuzz import fuzz
from sentence_transformers import SentenceTransformer, util
import os
import numpy as np

st.title("–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")

# –í—Å–µ–≥–¥–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–∑ grouped_categories.csv
csv_path = os.path.join(os.path.dirname(__file__), '..', 'grouped_categories.csv')
try:
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º session state –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π
    if 'df_param' not in st.session_state:
        st.session_state['df_param'] = pd.read_csv(csv_path, encoding='utf-8-sig')
    df_param = st.session_state['df_param']
    st.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ grouped_categories.csv ({len(df_param)} —Å—Ç—Ä–æ–∫, {len(df_param.columns)} –∫–æ–ª–æ–Ω–æ–∫)")
except Exception as e:
    df_param = pd.DataFrame()
    st.session_state['df_param'] = df_param
    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å grouped_categories.csv: {e}")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ sentence-transformers ---
@st.cache_resource(show_spinner=False)
def get_st_model():
    return SentenceTransformer('distiluse-base-multilingual-cased', device='cpu')

# --- Record Linkage —Å—Ö–æ–∂–µ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫ ---
def record_linkage_similarity(col1, col2):
    """–ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Record Linkage –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫"""
    try:
        import recordlinkage as rl
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –∏–Ω–¥–µ–∫—Å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        indexer = rl.Index()
        indexer.full()
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–æ–ª–æ–Ω–æ–∫
        df_cols = pd.DataFrame({'column': [col1, col2]})
        candidate_links = indexer.index(df_cols)
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        compare_cl = rl.Compare()
        compare_cl.string('column', 'column', method='jarowinkler', threshold=0.0)
        
        features = compare_cl.compute(candidate_links, df_cols)
        if len(features) > 0:
            return float(features.iloc[0, 0]) * 100
        return 0
    except ImportError:
        # Fallback –µ—Å–ª–∏ recordlinkage –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é Jaro-Winkler —Å—Ö–æ–∂–µ—Å—Ç—å —á–µ—Ä–µ–∑ rapidfuzz
        from rapidfuzz.distance import JaroWinkler
        return int(JaroWinkler.similarity(col1, col2) * 100)
    except Exception:
        return 0

# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —É–º–Ω–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è ---
def check_column_compatibility(df, col1, col2, smart_merge=True):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –¥–≤—É—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
    
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        col1, col2: –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        smart_merge: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —É–º–Ω—É—é –ª–æ–≥–∏–∫—É –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
    
    Returns:
        dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
    """
    result = {
        'compatible': True,
        'reason': '',
        'sources_different': False,
        'non_conflicting': True,
        'conflicts_count': 0,
        'both_filled_count': 0,
        'total_rows': len(df)
    }
    
    if not smart_merge:
        return result
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –†–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    if 'source_file' in df.columns:
        sources1 = set(df[df[col1].notna()]['source_file'])
        sources2 = set(df[df[col2].notna()]['source_file'])
        if sources1 and sources2:
            result['sources_different'] = len(sources1 & sources2) < max(len(sources1), len(sources2))
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ù–µ–ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è/—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    both_filled = df[(df[col1].notna()) & (df[col2].notna())]
    result['both_filled_count'] = len(both_filled)
    
    if len(both_filled) > 0:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è (—Ä–∞–∑–Ω—ã–µ –Ω–µ–ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        conflicts = both_filled[both_filled[col1].astype(str) != both_filled[col2].astype(str)]
        result['conflicts_count'] = len(conflicts)
        
        # –ï—Å–ª–∏ –±–æ–ª—å—à–µ 10% –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤, —Å—á–∏—Ç–∞–µ–º –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏
        conflict_ratio = len(conflicts) / len(both_filled)
        if conflict_ratio > 0.1:
            result['non_conflicting'] = False
            result['reason'] = f"–ú–Ω–æ–≥–æ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤: {len(conflicts)}/{len(both_filled)} ({conflict_ratio:.1%})"
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
    result['compatible'] = result['sources_different'] or result['non_conflicting']
    
    if not result['compatible']:
        if not result['sources_different'] and not result['non_conflicting']:
            result['reason'] = "–û–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ò –µ—Å—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∑–Ω–∞—á–µ–Ω–∏–π"
    
    return result

if not df_param.empty:
    st.dataframe(df_param.head(20))
    all_columns = list(df_param.columns)

    # --- –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è ---
    default_excluded_cols = [
        col for col in all_columns
        if 'name' in col.lower() or 'id' in col.lower() or 'source_file' in col.lower()
    ]

    st.markdown("#### –ò—Å–∫–ª—é—á–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    excluded_cols = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω–æ –≤–∫–ª—é—á–∞—Ç—å –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–∞—Ä:",
        options=all_columns,
        default=default_excluded_cols
    )

    columns = [c for c in all_columns if c not in excluded_cols]

    st.markdown("#### 1. –í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥—ã –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫")
    
    # --- Checkboxes for method selection ---
    col1, col2, col3 = st.columns(3)
    with col1:
        use_rapidfuzz = st.checkbox("RapidFuzz", value=True, key="use_rapidfuzz")
    with col2:
        use_sentence_transformers = st.checkbox("Sentence-Transformers", value=False, key="use_st")
    with col3:
        use_record_linkage = st.checkbox("Record Linkage", value=False, key="use_rl", 
                                       help="–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install recordlinkage")
    
    # --- Individual Threshold Sliders ---
    rf_threshold = None
    st_threshold = None
    rl_threshold = None
    
    if use_rapidfuzz:
        rf_threshold = st.slider("–ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è RapidFuzz (%)", 60, 100, 85, 1, key="rf_thresh")
    
    if use_sentence_transformers:
        st_threshold = st.slider("–ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è Sentence-Transformers (%)", 60, 100, 75, 1, key="st_thresh")
    
    if use_record_linkage:
        rl_threshold = st.slider("–ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è Record Linkage (%)", 60, 100, 80, 1, key="rl_thresh")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–∞—Ö
    selected_methods = []
    if use_rapidfuzz: selected_methods.append("RapidFuzz")
    if use_sentence_transformers: selected_methods.append("Sentence-Transformers") 
    if use_record_linkage: selected_methods.append("Record Linkage")
    
    if selected_methods:
        st.info(f"–í—ã–±—Ä–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã: {', '.join(selected_methods)}")
    else:
        st.warning("–ù–µ –≤—ã–±—Ä–∞–Ω –Ω–∏ –æ–¥–∏–Ω –º–µ—Ç–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è!")

    group_diff_sources = st.checkbox(
        "–£–º–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ: —Ç–æ–ª—å–∫–æ –Ω–µ–ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è –∑–Ω–∞—á–µ–Ω–∏—è",
        value=True,
        help="""–ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ, –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞:
        1. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (source_file), –ò/–ò–õ–ò
        2. –£ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–ê –∏–ª–∏ –ë, –Ω–æ –Ω–µ –æ–±–∞)
        –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Ç–µ—Ä—é –¥–∞–Ω–Ω—ã—Ö –∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∑–Ω–∞—á–µ–Ω–∏–π."""
    )
    
    # --- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø–∞—Ä—ã ---
    with st.expander("#### 2. üîç –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ–ª–æ–Ω–æ–∫", expanded=True):
        st.markdown("**–ü–æ–∏—Å–∫ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –ø—Ä–æ—Ü–µ—Å—Å–∞
        if 'start_search' not in st.session_state:
            st.session_state['start_search'] = False
        if 'confirmed_long' not in st.session_state:
            st.session_state['confirmed_long'] = False
        
        # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –ø–æ–∏—Å–∫–∞
        if st.button("üîç –ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ –∫–æ–ª–æ–Ω–∫–∏", key="find_similar"):
            if len(columns) == 0:
                st.warning("–ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è.")
            elif not any([use_rapidfuzz, use_sentence_transformers, use_record_linkage]):
                st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –º–µ—Ç–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è!")
            elif len(columns) > 100:
                st.error(f"‚ùå –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {len(columns)}. –ú–∞–∫—Å–∏–º—É–º 100 –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∑–∞–≤–∏—Å–∞–Ω–∏—è!")
            elif len(columns) > 30:
                st.warning(f"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –≤—ã–±—Ä–∞–Ω–æ {len(columns)} –∫–æ–ª–æ–Ω–æ–∫. –≠—Ç–æ –∑–∞–π–º–µ—Ç {len(columns)*(len(columns)-1)//2} —Å—Ä–∞–≤–Ω–µ–Ω–∏–π –∏ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è!")
                st.session_state['start_search'] = True
                st.session_state['confirmed_long'] = False
            else:
                st.session_state['start_search'] = True
                st.session_state['confirmed_long'] = True
        
        # –ï—Å–ª–∏ –º–Ω–æ–≥–æ –∫–æ–ª–æ–Ω–æ–∫, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
        if st.session_state['start_search'] and not st.session_state['confirmed_long']:
            if st.checkbox("–Ø –ø–æ–Ω–∏–º–∞—é, —á—Ç–æ —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è", key="confirm_long"):
                st.session_state['confirmed_long'] = True
                st.rerun()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ –µ—Å–ª–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ
        if st.session_state['start_search'] and st.session_state['confirmed_long']:
            similar_pairs = []
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
            active_methods = sum([
                use_rapidfuzz and rf_threshold is not None,
                use_sentence_transformers and st_threshold is not None, 
                use_record_linkage and rl_threshold is not None
            ])
            
            comparisons_per_method = len(columns) * (len(columns) - 1) // 2
            total_comparisons = comparisons_per_method * active_methods
            
            st.info(f"–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è {total_comparisons} —Å—Ä–∞–≤–Ω–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é {active_methods} –º–µ—Ç–æ–¥–æ–≤...")
            
            # –°–æ–∑–¥–∞–µ–º progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()
            comparison_count = 0
            
            # RapidFuzz method
            if use_rapidfuzz and rf_threshold is not None:
                status_text.text("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∏—Å–∫ —Å –ø–æ–º–æ—â—å—é RapidFuzz...")
                with st.spinner("–ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é RapidFuzz..."):
                    for i in range(len(columns)):
                        for j in range(i+1, len(columns)):
                            col1, col2 = columns[i], columns[j]
                            comparison_count += 1
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º progress bar –∫–∞–∂–¥—ã–µ 10 —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
                            if comparison_count % 10 == 0:
                                progress_bar.progress(comparison_count / total_comparisons)
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫
                            compatibility = check_column_compatibility(df_param, col1, col2, group_diff_sources)
                            if not compatibility['compatible']:
                                continue
                            
                            rf_score = fuzz.token_sort_ratio(col1, col2)
                            if rf_score >= rf_threshold:
                                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                                count1 = df_param[col1].notna().sum()
                                count2 = df_param[col2].notna().sum()
                                overlap = df_param[(df_param[col1].notna()) & (df_param[col2].notna())].shape[0]
                                
                                similar_pairs.append({
                                    "–ö–æ–ª–æ–Ω–∫–∞ 1": col1,
                                    "–ö–æ–ª–æ–Ω–∫–∞ 2": col2,
                                    "–°—Ö–æ–∂–µ—Å—Ç—å %": rf_score,
                                    "–ú–µ—Ç–æ–¥": "RapidFuzz",
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 1": count1,
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 2": count2,
                                    "–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π": overlap,
                                    "–ö–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤": compatibility['conflicts_count'],
                                    "–†–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏": "‚úÖ" if compatibility['sources_different'] else "‚ùå",
                                    "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª": count1 + count2 - overlap
                                })
            
            # Sentence-Transformers method
            if use_sentence_transformers and st_threshold is not None:
                status_text.text("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∏—Å–∫ —Å –ø–æ–º–æ—â—å—é Sentence-Transformers...")
                with st.spinner("–ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é Sentence-Transformers..."):
                    st_model = get_st_model()
                    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ embeddings –û–î–ò–ù –†–ê–ó
                    embeddings = st_model.encode(columns, convert_to_tensor=True)
                    
                    for i in range(len(columns)):
                        for j in range(i+1, len(columns)):
                            col1, col2 = columns[i], columns[j]
                            comparison_count += 1
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º progress bar –∫–∞–∂–¥—ã–µ 10 —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
                            if comparison_count % 10 == 0:
                                progress_bar.progress(comparison_count / total_comparisons)
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫
                            compatibility = check_column_compatibility(df_param, col1, col2, group_diff_sources)
                            if not compatibility['compatible']:
                                continue
                            
                            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å (–∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –≥–æ—Ç–æ–≤—ã–µ embeddings)
                            st_score = int(util.cos_sim(embeddings[i], embeddings[j]).item() * 100)
                            if st_score >= st_threshold:
                                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                                count1 = df_param[col1].notna().sum()
                                count2 = df_param[col2].notna().sum()
                                overlap = df_param[(df_param[col1].notna()) & (df_param[col2].notna())].shape[0]
                                
                                similar_pairs.append({
                                    "–ö–æ–ª–æ–Ω–∫–∞ 1": col1,
                                    "–ö–æ–ª–æ–Ω–∫–∞ 2": col2,
                                    "–°—Ö–æ–∂–µ—Å—Ç—å %": st_score,
                                    "–ú–µ—Ç–æ–¥": "SentenceTransformers",
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 1": count1,
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 2": count2,
                                    "–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π": overlap,
                                    "–ö–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤": compatibility['conflicts_count'],
                                    "–†–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏": "‚úÖ" if compatibility['sources_different'] else "‚ùå",
                                    "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª": count1 + count2 - overlap
                                })
            
            # Record Linkage method
            if use_record_linkage and rl_threshold is not None:
                status_text.text("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∏—Å–∫ —Å –ø–æ–º–æ—â—å—é Record Linkage...")
                with st.spinner("–ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é Record Linkage..."):
                    for i in range(len(columns)):
                        for j in range(i+1, len(columns)):
                            col1, col2 = columns[i], columns[j]
                            comparison_count += 1
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º progress bar –∫–∞–∂–¥—ã–µ 10 —Å—Ä–∞–≤–Ω–µ–Ω–∏–π
                            if comparison_count % 10 == 0:
                                progress_bar.progress(comparison_count / total_comparisons)
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫
                            compatibility = check_column_compatibility(df_param, col1, col2, group_diff_sources)
                            if not compatibility['compatible']:
                                continue
                            
                            rl_score = record_linkage_similarity(col1, col2)
                            if rl_score >= rl_threshold:
                                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                                count1 = df_param[col1].notna().sum()
                                count2 = df_param[col2].notna().sum()
                                overlap = df_param[(df_param[col1].notna()) & (df_param[col2].notna())].shape[0]
                                
                                similar_pairs.append({
                                    "–ö–æ–ª–æ–Ω–∫–∞ 1": col1,
                                    "–ö–æ–ª–æ–Ω–∫–∞ 2": col2,
                                    "–°—Ö–æ–∂–µ—Å—Ç—å %": int(rl_score),
                                    "–ú–µ—Ç–æ–¥": "RecordLinkage",
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 1": count1,
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 2": count2,
                                    "–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π": overlap,
                                    "–ö–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤": compatibility['conflicts_count'],
                                    "–†–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏": "‚úÖ" if compatibility['sources_different'] else "‚ùå",
                                    "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª": count1 + count2 - overlap
                                })
            
            # –ó–∞–≤–µ—Ä—à–∞–µ–º progress bar
            status_text.text("–ó–∞–≤–µ—Ä—à–µ–Ω–æ!")
            progress_bar.progress(1.0)
            progress_bar.empty()
            status_text.empty()
            
            # Remove duplicates and create DataFrame
            seen_pairs = set()
            unique_pairs = []
            for pair in similar_pairs:
                pair_key = tuple(sorted([pair["–ö–æ–ª–æ–Ω–∫–∞ 1"], pair["–ö–æ–ª–æ–Ω–∫–∞ 2"]]))
                if pair_key not in seen_pairs:
                    seen_pairs.add(pair_key)
                    unique_pairs.append(pair)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ session state
            if unique_pairs:
                sim_col_df = pd.DataFrame(unique_pairs).sort_values("–°—Ö–æ–∂–µ—Å—Ç—å %", ascending=False)
                st.session_state['similar_pairs_df'] = sim_col_df
                st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(unique_pairs)} –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ä!")
            else:
                st.info("–ü–æ—Ö–æ–∂–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ —Ç–µ–∫—É—â–∏–º –ø–æ—Ä–æ–≥–∞–º.")
                st.session_state['similar_pairs_df'] = pd.DataFrame()
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–∏—Å–∫–∞
            st.session_state['start_search'] = False
            st.session_state['confirmed_long'] = False

        # --- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ä ---
        if 'similar_pairs_df' in st.session_state and not st.session_state['similar_pairs_df'].empty:
            sim_col_df = st.session_state['similar_pairs_df']
            
            st.markdown("**üìã –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ—Ö–æ–∂–∏–µ –ø–∞—Ä—ã**")
            st.dataframe(sim_col_df, use_container_width=True)
            
            # –ú–∞—Å—Å–æ–≤–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ä
            col1, col2 = st.columns(2)
            with col1:
                if st.button("‚úÖ –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø–∞—Ä—ã", key="merge_all_auto"):
                    merged_count = 0
                    for _, row in sim_col_df.iterrows():
                        col_a, col_b = row["–ö–æ–ª–æ–Ω–∫–∞ 1"], row["–ö–æ–ª–æ–Ω–∫–∞ 2"]
                        new_col_name = f"{col_a}_{col_b}_merged"
                        if new_col_name not in df_param.columns:
                            df_param[new_col_name] = df_param[col_a].combine_first(df_param[col_b])
                            merged_count += 1
                    
                    if merged_count > 0:
                        # –û–±–Ω–æ–≤–ª—è–µ–º session state
                        st.session_state['df_param'] = df_param
                        st.success(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {merged_count} –ø–∞—Ä –∫–æ–ª–æ–Ω–æ–∫! –ù–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º '_merged'.")
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                        merged_cols = [col for col in df_param.columns if '_merged' in col]
                        if merged_cols:
                            st.markdown("**–ü—Ä–∏–º–µ—Ä—ã –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫:**")
                            st.dataframe(df_param[merged_cols].head(5))
                    else:
                        st.info("–í—Å–µ –ø–∞—Ä—ã —É–∂–µ –±—ã–ª–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã —Ä–∞–Ω–µ–µ.")
            
            with col2:
                if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞", key="clear_results"):
                    st.session_state['similar_pairs_df'] = pd.DataFrame()
                    st.rerun()

    # --- –í—ã–±–æ—Ä–æ—á–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ ---
    with st.expander("#### 3. üéØ –í—ã–±–æ—Ä–æ—á–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–∞—Ä", expanded=False):
        if 'similar_pairs_df' in st.session_state and not st.session_state['similar_pairs_df'].empty:
            sim_col_df = st.session_state['similar_pairs_df']
            
            selected_idx = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä—É –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è:",
                options=range(len(sim_col_df)),
                format_func=lambda x: f"{sim_col_df.iloc[x]['–ö–æ–ª–æ–Ω–∫–∞ 1']} ‚Üî {sim_col_df.iloc[x]['–ö–æ–ª–æ–Ω–∫–∞ 2']} ({sim_col_df.iloc[x]['–°—Ö–æ–∂–µ—Å—Ç—å %']}% - {sim_col_df.iloc[x]['–ú–µ—Ç–æ–¥']})",
                key="selected_pair"
            )
            
            if selected_idx is not None:
                selected_row = sim_col_df.iloc[selected_idx]
                col_a, col_b = selected_row["–ö–æ–ª–æ–Ω–∫–∞ 1"], selected_row["–ö–æ–ª–æ–Ω–∫–∞ 2"]
                
                # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
                st.markdown("**–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è:**")
                preview_df = df_param[[col_a, col_b]].copy()
                preview_df[f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π_—Ä–µ–∑—É–ª—å—Ç–∞—Ç"] = preview_df[col_a].combine_first(preview_df[col_b])
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã
                conflicts = preview_df[(preview_df[col_a].notna()) & (preview_df[col_b].notna()) & 
                                      (preview_df[col_a].astype(str) != preview_df[col_b].astype(str))]
                if len(conflicts) > 0:
                    st.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(conflicts)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –∑–Ω–∞—á–µ–Ω–∏–π:")
                    st.dataframe(conflicts.head(5))
                    st.info("üí° –ü—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–µ–∑–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                col_stat1, col_stat2, col_stat3 = st.columns(3)
                with col_stat1:
                    st.metric("–ó–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ –∫–æ–ª–æ–Ω–∫–µ 1", preview_df[col_a].notna().sum())
                with col_stat2:
                    st.metric("–ó–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ –∫–æ–ª–æ–Ω–∫–µ 2", preview_df[col_b].notna().sum())
                with col_stat3:
                    st.metric("–ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è", preview_df[f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π_—Ä–µ–∑—É–ª—å—Ç–∞—Ç"].notna().sum())
                
                st.dataframe(preview_df.head(10))
                
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
                new_col_name = st.text_input(
                    "–ò–º—è –¥–ª—è –Ω–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏:", 
                    value=f"{col_a}_{col_b}_merged",
                    key="custom_merge_name"
                )
                
                if st.button("‚úÖ –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—É—é –ø–∞—Ä—É", key="merge_selected"):
                    if new_col_name and new_col_name not in df_param.columns:
                        df_param[new_col_name] = df_param[col_a].combine_first(df_param[col_b])
                        # –û–±–Ω–æ–≤–ª—è–µ–º session state
                        st.session_state['df_param'] = df_param
                        st.success(f"–ü–∞—Ä–∞ '{col_a}' –∏ '{col_b}' –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∞ –≤ –∫–æ–ª–æ–Ω–∫—É '{new_col_name}'!")
                        # –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é –ø–∞—Ä—É –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        st.session_state['similar_pairs_df'] = sim_col_df.drop(selected_idx).reset_index(drop=True)
                        st.rerun()
                    elif new_col_name in df_param.columns:
                        st.error(f"–ö–æ–ª–æ–Ω–∫–∞ '{new_col_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
                    else:
                        st.error("–í–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –¥–ª—è –Ω–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏!")
        else:
            st.info("–°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–∏—Ç–µ –ø–æ—Ö–æ–∂–∏–µ –ø–∞—Ä—ã –≤ —Ä–∞–∑–¥–µ–ª–µ –≤—ã—à–µ")

    # --- –†—É—á–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ ---
    with st.expander("#### 4. ‚öôÔ∏è –†—É—á–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            col_a = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ 1", all_columns, key="merge_col_a_param")
        with col2:
            col_b = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ 2", [c for c in all_columns if c != col_a], key="merge_col_b_param")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
        if col_a and col_b:
            compatibility = check_column_compatibility(df_param, col_a, col_b, True)
            
            if compatibility['compatible']:
                st.success(f"‚úÖ –ö–æ–ª–æ–Ω–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
            else:
                st.warning(f"‚ö†Ô∏è –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã: {compatibility['reason']}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
            with stat_col1:
                st.metric("–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π", compatibility['both_filled_count'])
            with stat_col2:
                st.metric("–ö–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤", compatibility['conflicts_count'])
            with stat_col3:
                st.metric("–†–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏", "–î–∞" if compatibility['sources_different'] else "–ù–µ—Ç")
            with stat_col4:
                conflict_ratio = compatibility['conflicts_count'] / max(compatibility['both_filled_count'], 1) * 100
                st.metric("% –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤", f"{conflict_ratio:.1f}%")
        
        new_col_name = st.text_input("–ù–æ–≤–æ–µ –∏–º—è –¥–ª—è –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏", value=f"{col_a}_{col_b}_merged", key="merge_col_name_param")
        if st.button("–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å", key="merge_btn_param"):
            if col_a and col_b and new_col_name:
                df_param[new_col_name] = df_param[col_a].combine_first(df_param[col_b])
                # –û–±–Ω–æ–≤–ª—è–µ–º session state
                st.session_state['df_param'] = df_param
                st.success(f"–ö–æ–ª–æ–Ω–∫–∏ '{col_a}' –∏ '{col_b}' –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –≤ '{new_col_name}' –∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã.")
                st.dataframe(df_param[[col_a, col_b, new_col_name]].head(10))
            else:
                st.warning("–í—ã–±–µ—Ä–∏—Ç–µ –æ–±–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –≤–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –∏–º—è.")

    # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
    with st.expander("#### 5. üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", expanded=False):
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        if 'df_param' in st.session_state:
            current_df = st.session_state['df_param']
            st.info(f"üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: {len(current_df)} —Å—Ç—Ä–æ–∫, {len(current_df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            merged_count = len([col for col in current_df.columns if '_merged' in col])
            if merged_count > 0:
                st.success(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {merged_count}")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ grouped_categories.csv", key="save_main"):
                try:
                    output_path = os.path.join(os.path.dirname(__file__), '..', 'grouped_categories.csv')
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ session state
                    current_df = st.session_state.get('df_param', df_param)
                    current_df.to_csv(output_path, index=False, encoding='utf-8-sig')
                    st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
                    st.success(f"üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(current_df)} —Å—Ç—Ä–æ–∫, {len(current_df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
        
        with col2:
            if st.button("üì• –°–∫–∞—á–∞—Ç—å –∫–∞–∫ CSV", key="download_csv"):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ session state
                current_df = st.session_state.get('df_param', df_param)
                csv_data = current_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª",
                    data=csv_data,
                    file_name="processed_parameters.csv",
                    mime="text/csv",
                    key="download_processed"
                )
        
        with col3:
            if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", key="reload_data"):
                # –û—á–∏—â–∞–µ–º –∫—ç—à –∏ session state
                st.cache_data.clear()
                st.cache_resource.clear()
                if 'df_param' in st.session_state:
                    del st.session_state['df_param']
                if 'similar_pairs_df' in st.session_state:
                    del st.session_state['similar_pairs_df']
                st.success("–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã! –°—Ç—Ä–∞–Ω–∏—Ü–∞ –±—É–¥–µ—Ç –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
                st.rerun()

    # --- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º ---
    with st.expander("#### 6. üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º", expanded=False):
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ session state
        current_df = st.session_state.get('df_param', df_param)
        total_cols = len(current_df.columns)
        merged_cols = len([col for col in current_df.columns if '_merged' in col])
        total_rows = len(current_df)
        
        stat_col1, stat_col2, stat_col3 = st.columns(3)
        with stat_col1:
            st.metric("–í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫", total_cols)
        with stat_col2:
            st.metric("–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫", merged_cols)
        with stat_col3:
            st.metric("–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", total_rows)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ", key="show_all_data"):
            st.dataframe(current_df, use_container_width=True)
        else:
            st.markdown("**–ü–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫:**")
            st.dataframe(current_df.head(20), use_container_width=True)

else:
    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –≥–ª–∞–≤–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏.")
