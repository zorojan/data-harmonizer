import streamlit as st
import pandas as pd
from rapidfuzz import fuzz
from sentence_transformers import SentenceTransformer, util
import os
import numpy as np

st.title("–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")

# –í—Å–µ–≥–¥–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–∑ grouped_categories.csv
csv_path = os.path.join(os.path.dirname(__file__), '..', 'grouped_categories.csv')
try:
    df_param = pd.read_csv(csv_path, encoding='utf-8-sig')
    st.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ grouped_categories.csv")
except Exception as e:
    df_param = pd.DataFrame()
    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å grouped_categories.csv: {e}")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ sentence-transformers ---
@st.cache_resource(show_spinner=False)
def get_st_model():
    return SentenceTransformer('distiluse-base-multilingual-cased', device='cpu')

# --- Record Linkage —Å—Ö–æ–∂–µ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫ ---
def record_linkage_similarity(col1, col2):
    """–ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Record Linkage –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫"""
    try:
        import recordlinkage as rl
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –∏–Ω–¥–µ–∫—Å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        indexer = rl.Index()
        indexer.full()
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–æ–ª–æ–Ω–æ–∫
        df_cols = pd.DataFrame({'column': [col1, col2]})
        candidate_links = indexer.index(df_cols)
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        compare_cl = rl.Compare()
        compare_cl.string('column', 'column', method='jarowinkler', threshold=0.0)
        
        features = compare_cl.compute(candidate_links, df_cols)
        if len(features) > 0:
            return float(features.iloc[0, 0]) * 100
        return 0
    except ImportError:
        # Fallback –µ—Å–ª–∏ recordlinkage –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é Jaro-Winkler —Å—Ö–æ–∂–µ—Å—Ç—å —á–µ—Ä–µ–∑ rapidfuzz
        from rapidfuzz.distance import JaroWinkler
        return int(JaroWinkler.similarity(col1, col2) * 100)
    except Exception:
        return 0

# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —É–º–Ω–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è ---
def check_column_compatibility(df, col1, col2, smart_merge=True):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –¥–≤—É—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
    
    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        col1, col2: –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        smart_merge: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —É–º–Ω—É—é –ª–æ–≥–∏–∫—É –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
    
    Returns:
        dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
    """
    result = {
        'compatible': True,
        'reason': '',
        'sources_different': False,
        'non_conflicting': True,
        'conflicts_count': 0,
        'both_filled_count': 0,
        'total_rows': len(df)
    }
    
    if not smart_merge:
        return result
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –†–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    if 'source_file' in df.columns:
        sources1 = set(df[df[col1].notna()]['source_file'])
        sources2 = set(df[df[col2].notna()]['source_file'])
        if sources1 and sources2:
            result['sources_different'] = len(sources1 & sources2) < max(len(sources1), len(sources2))
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ù–µ–ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è/—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    both_filled = df[(df[col1].notna()) & (df[col2].notna())]
    result['both_filled_count'] = len(both_filled)
    
    if len(both_filled) > 0:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è (—Ä–∞–∑–Ω—ã–µ –Ω–µ–ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        conflicts = both_filled[both_filled[col1].astype(str) != both_filled[col2].astype(str)]
        result['conflicts_count'] = len(conflicts)
        
        # –ï—Å–ª–∏ –±–æ–ª—å—à–µ 10% –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤, —Å—á–∏—Ç–∞–µ–º –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏
        conflict_ratio = len(conflicts) / len(both_filled)
        if conflict_ratio > 0.1:
            result['non_conflicting'] = False
            result['reason'] = f"–ú–Ω–æ–≥–æ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤: {len(conflicts)}/{len(both_filled)} ({conflict_ratio:.1%})"
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
    result['compatible'] = result['sources_different'] or result['non_conflicting']
    
    if not result['compatible']:
        if not result['sources_different'] and not result['non_conflicting']:
            result['reason'] = "–û–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ò –µ—Å—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∑–Ω–∞—á–µ–Ω–∏–π"
    
    return result

if not df_param.empty:
    st.dataframe(df_param.head(20))
    all_columns = list(df_param.columns)

    # --- –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è ---
    default_excluded_cols = [
        col for col in all_columns
        if 'name' in col.lower() or 'id' in col.lower() or 'source_file' in col.lower()
    ]

    st.markdown("#### –ò—Å–∫–ª—é—á–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    excluded_cols = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω–æ –≤–∫–ª—é—á–∞—Ç—å –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–∞—Ä:",
        options=all_columns,
        default=default_excluded_cols
    )

    columns = [c for c in all_columns if c not in excluded_cols]

    st.markdown("#### 1. –í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥—ã –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫")
    
    # --- Checkboxes for method selection ---
    col1, col2, col3 = st.columns(3)
    with col1:
        use_rapidfuzz = st.checkbox("RapidFuzz", value=True, key="use_rapidfuzz")
    with col2:
        use_sentence_transformers = st.checkbox("Sentence-Transformers", value=False, key="use_st")
    with col3:
        use_record_linkage = st.checkbox("Record Linkage", value=False, key="use_rl", 
                                       help="–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install recordlinkage")
    
    # --- Individual Threshold Sliders ---
    rf_threshold = None
    st_threshold = None
    rl_threshold = None
    
    if use_rapidfuzz:
        rf_threshold = st.slider("–ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è RapidFuzz (%)", 60, 100, 85, 1, key="rf_thresh")
    
    if use_sentence_transformers:
        st_threshold = st.slider("–ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è Sentence-Transformers (%)", 60, 100, 75, 1, key="st_thresh")
    
    if use_record_linkage:
        rl_threshold = st.slider("–ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è Record Linkage (%)", 60, 100, 80, 1, key="rl_thresh")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–∞—Ö
    selected_methods = []
    if use_rapidfuzz: selected_methods.append("RapidFuzz")
    if use_sentence_transformers: selected_methods.append("Sentence-Transformers") 
    if use_record_linkage: selected_methods.append("Record Linkage")
    
    if selected_methods:
        st.info(f"–í—ã–±—Ä–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã: {', '.join(selected_methods)}")
    else:
        st.warning("–ù–µ –≤—ã–±—Ä–∞–Ω –Ω–∏ –æ–¥–∏–Ω –º–µ—Ç–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è!")

    group_diff_sources = st.checkbox(
        "–£–º–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ: —Ç–æ–ª—å–∫–æ –Ω–µ–ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è –∑–Ω–∞—á–µ–Ω–∏—è",
        value=True,
        help="""–ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ, –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞:
        1. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (source_file), –ò/–ò–õ–ò
        2. –£ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–ê –∏–ª–∏ –ë, –Ω–æ –Ω–µ –æ–±–∞)
        –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Ç–µ—Ä—é –¥–∞–Ω–Ω—ã—Ö –∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∑–Ω–∞—á–µ–Ω–∏–π."""
    )
    
    # --- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ä ---
    st.markdown("#### 2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ–ª–æ–Ω–æ–∫")
    
    if st.button("üîç –ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ –∫–æ–ª–æ–Ω–∫–∏", key="find_similar"):
        if len(columns) == 0:
            st.warning("–ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è.")
        elif not any([use_rapidfuzz, use_sentence_transformers, use_record_linkage]):
            st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –º–µ—Ç–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è!")
        elif len(columns) > 50:
            st.warning(f"–í–Ω–∏–º–∞–Ω–∏–µ: –≤—ã–±—Ä–∞–Ω–æ {len(columns)} –∫–æ–ª–æ–Ω–æ–∫. –ê–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è!")
        else:
            similar_pairs = []
            
            # RapidFuzz method
            if use_rapidfuzz and rf_threshold is not None:
                with st.spinner("–ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é RapidFuzz..."):
                    for i in range(len(columns)):
                        for j in range(i+1, len(columns)):
                            col1, col2 = columns[i], columns[j]
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫
                            compatibility = check_column_compatibility(df_param, col1, col2, group_diff_sources)
                            if not compatibility['compatible']:
                                continue
                            
                            rf_score = fuzz.token_sort_ratio(col1, col2)
                            if rf_score >= rf_threshold:
                                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                                count1 = df_param[col1].notna().sum()
                                count2 = df_param[col2].notna().sum()
                                overlap = df_param[(df_param[col1].notna()) & (df_param[col2].notna())].shape[0]
                                
                                similar_pairs.append({
                                    "–ö–æ–ª–æ–Ω–∫–∞ 1": col1,
                                    "–ö–æ–ª–æ–Ω–∫–∞ 2": col2,
                                    "–°—Ö–æ–∂–µ—Å—Ç—å %": rf_score,
                                    "–ú–µ—Ç–æ–¥": "RapidFuzz",
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 1": count1,
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 2": count2,
                                    "–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π": overlap,
                                    "–ö–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤": compatibility['conflicts_count'],
                                    "–†–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏": "‚úÖ" if compatibility['sources_different'] else "‚ùå",
                                    "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª": count1 + count2 - overlap
                                })
            
            # Sentence-Transformers method
            if use_sentence_transformers and st_threshold is not None:
                with st.spinner("–ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é Sentence-Transformers..."):
                    st_model = get_st_model()
                    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ embeddings
                    embeddings = st_model.encode(columns, convert_to_tensor=True)
                    
                    for i in range(len(columns)):
                        for j in range(i+1, len(columns)):
                            col1, col2 = columns[i], columns[j]
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫
                            compatibility = check_column_compatibility(df_param, col1, col2, group_diff_sources)
                            if not compatibility['compatible']:
                                continue
                            
                            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
                            st_score = int(util.cos_sim(embeddings[i], embeddings[j]).item() * 100)
                            if st_score >= st_threshold:
                                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                                count1 = df_param[col1].notna().sum()
                                count2 = df_param[col2].notna().sum()
                                overlap = df_param[(df_param[col1].notna()) & (df_param[col2].notna())].shape[0]
                                
                                similar_pairs.append({
                                    "–ö–æ–ª–æ–Ω–∫–∞ 1": col1,
                                    "–ö–æ–ª–æ–Ω–∫–∞ 2": col2,
                                    "–°—Ö–æ–∂–µ—Å—Ç—å %": st_score,
                                    "–ú–µ—Ç–æ–¥": "SentenceTransformers",
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 1": count1,
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 2": count2,
                                    "–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π": overlap,
                                    "–ö–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤": compatibility['conflicts_count'],
                                    "–†–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏": "‚úÖ" if compatibility['sources_different'] else "‚ùå",
                                    "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª": count1 + count2 - overlap
                                })
            
            # Record Linkage method
            if use_record_linkage and rl_threshold is not None:
                with st.spinner("–ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é Record Linkage..."):
                    for i in range(len(columns)):
                        for j in range(i+1, len(columns)):
                            col1, col2 = columns[i], columns[j]
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫
                            compatibility = check_column_compatibility(df_param, col1, col2, group_diff_sources)
                            if not compatibility['compatible']:
                                continue
                            
                            rl_score = record_linkage_similarity(col1, col2)
                            if rl_score >= rl_threshold:
                                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                                count1 = df_param[col1].notna().sum()
                                count2 = df_param[col2].notna().sum()
                                overlap = df_param[(df_param[col1].notna()) & (df_param[col2].notna())].shape[0]
                                
                                similar_pairs.append({
                                    "–ö–æ–ª–æ–Ω–∫–∞ 1": col1,
                                    "–ö–æ–ª–æ–Ω–∫–∞ 2": col2,
                                    "–°—Ö–æ–∂–µ—Å—Ç—å %": int(rl_score),
                                    "–ú–µ—Ç–æ–¥": "RecordLinkage",
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 1": count1,
                                    "–ó–Ω–∞—á–µ–Ω–∏–π –≤ 2": count2,
                                    "–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π": overlap,
                                    "–ö–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤": compatibility['conflicts_count'],
                                    "–†–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏": "‚úÖ" if compatibility['sources_different'] else "‚ùå",
                                    "–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª": count1 + count2 - overlap
                                })
            
            # Remove duplicates and create DataFrame
            seen_pairs = set()
            unique_pairs = []
            for pair in similar_pairs:
                pair_key = tuple(sorted([pair["–ö–æ–ª–æ–Ω–∫–∞ 1"], pair["–ö–æ–ª–æ–Ω–∫–∞ 2"]]))
                if pair_key not in seen_pairs:
                    seen_pairs.add(pair_key)
                    unique_pairs.append(pair)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ session state
            if unique_pairs:
                sim_col_df = pd.DataFrame(unique_pairs).sort_values("–°—Ö–æ–∂–µ—Å—Ç—å %", ascending=False)
                st.session_state['similar_pairs_df'] = sim_col_df
                st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(unique_pairs)} –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ä!")
            else:
                st.info("–ü–æ—Ö–æ–∂–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ —Ç–µ–∫—É—â–∏–º –ø–æ—Ä–æ–≥–∞–º.")
                st.session_state['similar_pairs_df'] = pd.DataFrame()

    # --- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —Ä–∞–±–æ—Ç–∞ —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–∏ ---
    if 'similar_pairs_df' in st.session_state and not st.session_state['similar_pairs_df'].empty:
        sim_col_df = st.session_state['similar_pairs_df']
        
        st.markdown("#### 3. –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ—Ö–æ–∂–∏–µ –ø–∞—Ä—ã")
        st.dataframe(sim_col_df, use_container_width=True)
        
        # –ú–∞—Å—Å–æ–≤–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ä
        col1, col2 = st.columns(2)
        with col1:
            if st.button("‚úÖ –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø–∞—Ä—ã", key="merge_all_auto"):
                merged_count = 0
                for _, row in sim_col_df.iterrows():
                    col_a, col_b = row["–ö–æ–ª–æ–Ω–∫–∞ 1"], row["–ö–æ–ª–æ–Ω–∫–∞ 2"]
                    new_col_name = f"{col_a}_{col_b}_merged"
                    if new_col_name not in df_param.columns:
                        df_param[new_col_name] = df_param[col_a].combine_first(df_param[col_b])
                        merged_count += 1
                
                if merged_count > 0:
                    st.success(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {merged_count} –ø–∞—Ä –∫–æ–ª–æ–Ω–æ–∫! –ù–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º '_merged'.")
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    merged_cols = [col for col in df_param.columns if '_merged' in col]
                    if merged_cols:
                        st.markdown("**–ü—Ä–∏–º–µ—Ä—ã –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫:**")
                        st.dataframe(df_param[merged_cols].head(5))
                else:
                    st.info("–í—Å–µ –ø–∞—Ä—ã —É–∂–µ –±—ã–ª–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã —Ä–∞–Ω–µ–µ.")
        
        with col2:
            if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞", key="clear_results"):
                st.session_state['similar_pairs_df'] = pd.DataFrame()
                st.rerun()
        
        # –í—ã–±–æ—Ä–æ—á–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–∞—Ä
        st.markdown("#### 4. –í—ã–±–æ—Ä–æ—á–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ")
        selected_idx = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä—É –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è:",
            options=range(len(sim_col_df)),
            format_func=lambda x: f"{sim_col_df.iloc[x]['–ö–æ–ª–æ–Ω–∫–∞ 1']} ‚Üî {sim_col_df.iloc[x]['–ö–æ–ª–æ–Ω–∫–∞ 2']} ({sim_col_df.iloc[x]['–°—Ö–æ–∂–µ—Å—Ç—å %']}% - {sim_col_df.iloc[x]['–ú–µ—Ç–æ–¥']})",
            key="selected_pair"
        )
        
        if selected_idx is not None:
            selected_row = sim_col_df.iloc[selected_idx]
            col_a, col_b = selected_row["–ö–æ–ª–æ–Ω–∫–∞ 1"], selected_row["–ö–æ–ª–æ–Ω–∫–∞ 2"]
            
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
            st.markdown("**–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è:**")
            preview_df = df_param[[col_a, col_b]].copy()
            preview_df[f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π_—Ä–µ–∑—É–ª—å—Ç–∞—Ç"] = preview_df[col_a].combine_first(preview_df[col_b])
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã
            conflicts = preview_df[(preview_df[col_a].notna()) & (preview_df[col_b].notna()) & 
                                  (preview_df[col_a].astype(str) != preview_df[col_b].astype(str))]
            if len(conflicts) > 0:
                st.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {len(conflicts)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –∑–Ω–∞—á–µ–Ω–∏–π:")
                st.dataframe(conflicts.head(5))
                st.info("üí° –ü—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–µ–∑–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            col_stat1, col_stat2, col_stat3 = st.columns(3)
            with col_stat1:
                st.metric("–ó–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ –∫–æ–ª–æ–Ω–∫–µ 1", preview_df[col_a].notna().sum())
            with col_stat2:
                st.metric("–ó–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ –∫–æ–ª–æ–Ω–∫–µ 2", preview_df[col_b].notna().sum())
            with col_stat3:
                st.metric("–ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è", preview_df[f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π_—Ä–µ–∑—É–ª—å—Ç–∞—Ç"].notna().sum())
            
            st.dataframe(preview_df.head(10))
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
            new_col_name = st.text_input(
                "–ò–º—è –¥–ª—è –Ω–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏:", 
                value=f"{col_a}_{col_b}_merged",
                key="custom_merge_name"
            )
            
            if st.button("‚úÖ –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—É—é –ø–∞—Ä—É", key="merge_selected"):
                if new_col_name and new_col_name not in df_param.columns:
                    df_param[new_col_name] = df_param[col_a].combine_first(df_param[col_b])
                    st.success(f"–ü–∞—Ä–∞ '{col_a}' –∏ '{col_b}' –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∞ –≤ –∫–æ–ª–æ–Ω–∫—É '{new_col_name}'!")
                    # –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é –ø–∞—Ä—É –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    st.session_state['similar_pairs_df'] = sim_col_df.drop(selected_idx).reset_index(drop=True)
                    st.rerun()
                elif new_col_name in df_param.columns:
                    st.error(f"–ö–æ–ª–æ–Ω–∫–∞ '{new_col_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
                else:
                    st.error("–í–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –¥–ª—è –Ω–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏!")

    st.markdown("#### 5. –†—É—á–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫")
    col1, col2 = st.columns(2)
    with col1:
        col_a = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ 1", all_columns, key="merge_col_a_param")
    with col2:
        col_b = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ 2", [c for c in all_columns if c != col_a], key="merge_col_b_param")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
    if col_a and col_b:
        compatibility = check_column_compatibility(df_param, col_a, col_b, True)
        
        if compatibility['compatible']:
            st.success(f"‚úÖ –ö–æ–ª–æ–Ω–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        else:
            st.warning(f"‚ö†Ô∏è –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã: {compatibility['reason']}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
        with stat_col1:
            st.metric("–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π", compatibility['both_filled_count'])
        with stat_col2:
            st.metric("–ö–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤", compatibility['conflicts_count'])
        with stat_col3:
            st.metric("–†–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏", "–î–∞" if compatibility['sources_different'] else "–ù–µ—Ç")
        with stat_col4:
            conflict_ratio = compatibility['conflicts_count'] / max(compatibility['both_filled_count'], 1) * 100
            st.metric("% –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤", f"{conflict_ratio:.1f}%")
    
    new_col_name = st.text_input("–ù–æ–≤–æ–µ –∏–º—è –¥–ª—è –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏", value=f"{col_a}_{col_b}_merged", key="merge_col_name_param")
    if st.button("–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å", key="merge_btn_param"):
        if col_a and col_b and new_col_name:
            df_param[new_col_name] = df_param[col_a].combine_first(df_param[col_b])
            st.success(f"–ö–æ–ª–æ–Ω–∫–∏ '{col_a}' –∏ '{col_b}' –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –≤ '{new_col_name}' –∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã.")
            st.dataframe(df_param[[col_a, col_b, new_col_name]].head(10))
        else:
            st.warning("–í—ã–±–µ—Ä–∏—Ç–µ –æ–±–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –≤–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –∏–º—è.")
    # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
    st.markdown("#### 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ grouped_categories.csv", key="save_main"):
            try:
                output_path = os.path.join(os.path.dirname(__file__), '..', 'grouped_categories.csv')
                df_param.to_csv(output_path, index=False, encoding='utf-8-sig')
                st.success(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
    
    with col2:
        if st.button("üì• –°–∫–∞—á–∞—Ç—å –∫–∞–∫ CSV", key="download_csv"):
            csv_data = df_param.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª",
                data=csv_data,
                file_name="processed_parameters.csv",
                mime="text/csv",
                key="download_processed"
            )
    
    with col3:
        if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", key="reload_data"):
            st.cache_data.clear()
            st.rerun()
    
    # --- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º ---
    st.markdown("#### 7. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º")
    
    total_cols = len(df_param.columns)
    merged_cols = len([col for col in df_param.columns if '_merged' in col])
    total_rows = len(df_param)
    
    stat_col1, stat_col2, stat_col3 = st.columns(3)
    with stat_col1:
        st.metric("–í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫", total_cols)
    with stat_col2:
        st.metric("–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫", merged_cols)
    with stat_col3:
        st.metric("–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", total_rows)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ", key="show_all_data"):
        st.dataframe(df_param, use_container_width=True)
    else:
        st.markdown("**–ü–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫:**")
        st.dataframe(df_param.head(20), use_container_width=True)

else:
    st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –≥–ª–∞–≤–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏.")
